# main.py - ASCOMIND+ STREAMLIT APPLICATION

import streamlit as st
import asyncio
import pandas as pd
import plotly.graph_objects as go
from typing import Dict, List, Any, Optional
import uuid
from datetime import datetime
import io
import json
import time  # Add time import for tracking processing duration

# Import agents and models
from agents.metadata_extractor import EnhancedMetadataExtractor, BatchExtractor
from agents.analyzer import IntelligentAnalyzer
from agents.visualizer import AdvancedVisualizer
from agents.categorizer import SmartCategorizer, BatchCategorizer
from agents.protocol_maker import ProtocolMaker
from agents.vector_store import IntelligentVectorStore
from agents.ai_assistant import AdvancedAIAssistant
from models.abstract_metadata import ComprehensiveAbstractMetadata
from config.settings import settings

# Import utilities
from utils.file_processors import FileProcessor, AbstractExtractor
from utils.database import get_database

# Set page configuration
st.set_page_config(
    page_title="ASCOmind+ | Medical Intelligence Platform",
    page_icon="üß¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Advanced Custom CSS for professional styling
st.markdown("""
<style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap');
    
    /* Global Variables */
    :root {
        --primary-color: #667eea;
        --secondary-color: #764ba2;
        --accent-color: #f093fb;
        --success-color: #4ade80;
        --warning-color: #fbbf24;
        --error-color: #f87171;
        --background-light: #f8fafc;
        --background-dark: #1e293b;
        --text-primary: #1e293b;
        --text-secondary: #64748b;
        --border-color: #e2e8f0;
        --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
        --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
        --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
    }
    
    /* Hide Streamlit default elements */
    .stDeployButton {display: none;}
    #MainMenu {visibility: hidden;}
    .stFooter {display: none;}
    header {visibility: hidden;}
    
    /* Main container styling */
    .main > div {
        padding-top: 1rem;
        font-family: 'Inter', sans-serif;
    }
    
    /* Header styling with enhanced gradient */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        padding: 2rem;
        border-radius: 1rem;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        position: relative;
        overflow: hidden;
        box-shadow: var(--shadow-xl);
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: linear-gradient(45deg, transparent 30%, rgba(255,255,255,0.1) 50%, transparent 70%);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { transform: translateX(-100%); }
        100% { transform: translateX(100%); }
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
        position: relative;
        z-index: 1;
    }
    
    .main-header p {
        font-size: 1.1rem;
        font-weight: 400;
        opacity: 0.9;
        position: relative;
        z-index: 1;
    }
    
    /* Enhanced metric cards */
    .metric-card {
        background: linear-gradient(145deg, #ffffff 0%, #f8fafc 100%);
        padding: 1.5rem;
        border-radius: 1rem;
        box-shadow: var(--shadow-md);
        border: 1px solid var(--border-color);
        border-left: 4px solid var(--primary-color);
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: var(--shadow-lg);
        border-left-color: var(--accent-color);
    }
    
    .metric-card::before {
        content: '';
        position: absolute;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: linear-gradient(135deg, var(--primary-color)20, transparent);
        border-radius: 0 1rem 0 100%;
    }
    
    .metric-card h4 {
        color: var(--text-primary);
        font-weight: 600;
        margin-bottom: 0.5rem;
        font-size: 1.1rem;
    }
    
    .metric-card p {
        color: var(--text-secondary);
        line-height: 1.5;
        margin: 0;
    }
    
    /* Advanced insight panel */
    .insight-panel {
        background: linear-gradient(145deg, #f8fafc 0%, #ffffff 100%);
        padding: 2rem;
        border-radius: 1rem;
        border: 1px solid var(--border-color);
        box-shadow: var(--shadow-md);
        position: relative;
    }
    
    .insight-panel::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 4px;
        background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
        border-radius: 1rem 1rem 0 0;
    }
    
    /* Enhanced buttons */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
        color: white;
        border: none;
        border-radius: 0.75rem;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
        font-family: 'Inter', sans-serif;
        transition: all 0.3s ease;
        box-shadow: var(--shadow-sm);
    }
    
    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: var(--shadow-md);
        background: linear-gradient(135deg, var(--secondary-color) 0%, var(--primary-color) 100%);
    }
    
    .stButton > button:active {
        transform: translateY(0);
    }
    
    /* Enhanced tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.25rem;
        background: var(--background-light);
        padding: 0.25rem;
        border-radius: 0.75rem;
        border: 1px solid var(--border-color);
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 3rem;
        padding: 0 1.5rem;
        border-radius: 0.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
        border: none;
        background: transparent;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white !important;
        box-shadow: var(--shadow-sm);
    }
    
    /* Enhanced sidebar */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8fafc 0%, #ffffff 100%);
        border-right: 1px solid var(--border-color);
    }
    
    /* Quality badges */
    .quality-badge {
        display: inline-flex;
        align-items: center;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        font-weight: 500;
        margin: 0.125rem;
    }
    
    .quality-high {
        background: linear-gradient(135deg, #10b981, #34d399);
        color: white;
        box-shadow: 0 2px 4px rgba(16, 185, 129, 0.3);
    }
    
    .quality-medium {
        background: linear-gradient(135deg, #f59e0b, #fbbf24);
        color: white;
        box-shadow: 0 2px 4px rgba(245, 158, 11, 0.3);
    }
    
    .quality-low {
        background: linear-gradient(135deg, #ef4444, #f87171);
        color: white;
        box-shadow: 0 2px 4px rgba(239, 68, 68, 0.3);
    }
    
    /* Enhanced progress bars */
    .stProgress > div > div > div {
        background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
        border-radius: 9999px;
    }
    
    /* Advanced dataframe styling */
    .stDataFrame {
        border-radius: 0.75rem;
        border: 1px solid var(--border-color);
        overflow: hidden;
        box-shadow: var(--shadow-sm);
    }
    
    .stDataFrame table {
        border-collapse: separate;
        border-spacing: 0;
    }
    
    .stDataFrame th {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        font-weight: 600;
        padding: 1rem;
        border: none;
    }
    
    .stDataFrame td {
        padding: 0.75rem 1rem;
        border-bottom: 1px solid var(--border-color);
        transition: background-color 0.2s ease;
    }
    
    .stDataFrame tr:hover td {
        background-color: var(--background-light);
    }
    
    /* Enhanced metrics */
    .stMetric {
        background: white;
        padding: 1rem;
        border-radius: 0.75rem;
        border: 1px solid var(--border-color);
        box-shadow: var(--shadow-sm);
        transition: all 0.3s ease;
    }
    
    .stMetric:hover {
        transform: translateY(-1px);
        box-shadow: var(--shadow-md);
    }
    
    .stMetric > div > div:first-child {
        color: var(--text-secondary);
        font-size: 0.875rem;
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.025em;
    }
    
    .stMetric > div > div:nth-child(2) {
        color: var(--text-primary);
        font-size: 1.5rem;
        font-weight: 700;
        margin: 0.25rem 0;
    }
    
    /* Enhanced expanders */
    .stExpander {
        border: 1px solid var(--border-color);
        border-radius: 0.75rem;
        overflow: hidden;
        margin-bottom: 1rem;
        box-shadow: var(--shadow-sm);
    }
    
    .stExpander > summary {
        background: linear-gradient(135deg, #f8fafc, #ffffff);
        padding: 1rem 1.5rem;
        font-weight: 500;
        border: none;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .stExpander > summary:hover {
        background: linear-gradient(135deg, var(--primary-color)10, var(--accent-color)10);
    }
    
    .stExpander[open] > summary {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
    }
    
    .stExpander > div {
        padding: 1.5rem;
        background: white;
    }
    
    /* Enhanced file uploader */
    .stFileUploader {
        border: 2px dashed var(--border-color);
        border-radius: 0.75rem;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
        background: linear-gradient(145deg, #ffffff, #f8fafc);
    }
    
    .stFileUploader:hover {
        border-color: var(--primary-color);
        background: linear-gradient(145deg, var(--primary-color)05, var(--accent-color)05);
    }
    
    /* Enhanced selectbox */
    .stSelectbox > div > div {
        border-radius: 0.5rem;
        border: 1px solid var(--border-color);
        background: white;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div:hover {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px var(--primary-color)20;
    }
    
    /* Enhanced text areas */
    .stTextArea > div > div > textarea {
        border-radius: 0.5rem;
        border: 1px solid var(--border-color);
        transition: all 0.3s ease;
        font-family: 'Inter', sans-serif;
    }
    
    .stTextArea > div > div > textarea:focus {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px var(--primary-color)20;
    }
    
    /* Loading animation */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    .loading {
        animation: pulse 2s infinite;
    }
    
    /* Status indicators */
    .status-indicator {
        display: inline-flex;
        align-items: center;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        font-weight: 500;
        margin: 0.125rem;
    }
    
    .status-processing {
        background: linear-gradient(135deg, #3b82f6, #60a5fa);
        color: white;
        animation: pulse 2s infinite;
    }
    
    .status-complete {
        background: linear-gradient(135deg, #10b981, #34d399);
        color: white;
    }
    
    .status-error {
        background: linear-gradient(135deg, #ef4444, #f87171);
        color: white;
    }
    
    /* Enhanced charts */
    .stPlotlyChart {
        border-radius: 0.75rem;
        border: 1px solid var(--border-color);
        overflow: hidden;
        box-shadow: var(--shadow-sm);
        background: white;
    }
    
    /* Responsive design */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2rem;
        }
        
        .metric-card {
            padding: 1rem;
        }
        
        .insight-panel {
            padding: 1.5rem;
        }
    }
    
    /* Custom scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: var(--background-light);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(135deg, var(--secondary-color), var(--primary-color));
    }
    
    /* Enhanced info boxes */
    .stInfo {
        background: linear-gradient(135deg, #dbeafe, #bfdbfe);
        border: 1px solid #3b82f6;
        border-radius: 0.75rem;
        color: #1e40af;
    }
    
    .stSuccess {
        background: linear-gradient(135deg, #d1fae5, #a7f3d0);
        border: 1px solid #10b981;
        border-radius: 0.75rem;
        color: #065f46;
    }
    
    .stWarning {
        background: linear-gradient(135deg, #fef3c7, #fde68a);
        border: 1px solid #f59e0b;
        border-radius: 0.75rem;
        color: #92400e;
    }
    
    .stError {
        background: linear-gradient(135deg, #fee2e2, #fecaca);
        border: 1px solid #ef4444;
        border-radius: 0.75rem;
        color: #991b1b;
    }
    
    /* Enhanced sidebar metrics */
    .sidebar-metric {
        background: white;
        padding: 1rem;
        border-radius: 0.75rem;
        border: 1px solid var(--border-color);
        margin-bottom: 0.5rem;
        box-shadow: var(--shadow-sm);
        transition: all 0.3s ease;
    }
    
    .sidebar-metric:hover {
        transform: translateY(-1px);
        box-shadow: var(--shadow-md);
    }
    
    /* Glassmorphism effect for special cards */
    .glass-card {
        background: rgba(255, 255, 255, 0.25);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.18);
        border-radius: 1rem;
        box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
    }
    
    /* Section headers */
    .section-header {
        display: flex;
        align-items: center;
        margin: 2rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid var(--border-color);
    }
    
    .section-header h2, .section-header h3 {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        margin: 0;
        font-weight: 700;
    }
    
    /* Custom navigation styles */
    .nav-button {
        display: block;
        width: 100%;
        padding: 1rem 1.5rem;
        margin-bottom: 0.5rem;
        border: none;
        border-radius: 0.75rem;
        background: linear-gradient(135deg, #f8fafc, #ffffff);
        color: #64748b;
        text-decoration: none;
        font-weight: 500;
        font-size: 0.95rem;
        cursor: pointer;
        transition: all 0.3s ease;
        border: 1px solid #e2e8f0;
        box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1);
    }
    
    .nav-button:hover {
        background: linear-gradient(135deg, #667eea20, #764ba220);
        border-color: #667eea;
        transform: translateY(-1px);
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        color: #1e293b;
    }
    
    .nav-button.active {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        border-color: #5a67d8;
        box-shadow: 0 4px 6px -1px rgba(102, 126, 234, 0.3);
    }
    
    .nav-button.active:hover {
        background: linear-gradient(135deg, #5a67d8, #6b46c1);
        transform: translateY(-1px);
        box-shadow: 0 6px 8px -1px rgba(102, 126, 234, 0.4);
    }
    
    .nav-icon {
        font-size: 1.25rem;
        margin-right: 0.75rem;
        display: inline-block;
        width: 24px;
        text-align: center;
    }
    
    .nav-text {
        display: inline-block;
        vertical-align: middle;
    }
    
    .nav-badge {
        float: right;
        background: rgba(255, 255, 255, 0.2);
        color: inherit;
        padding: 0.125rem 0.5rem;
        border-radius: 9999px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-left: 0.5rem;
    }
    
    .info-card {
        background: linear-gradient(135deg, #f8fafc, #e2e8f0);
        border: 1px solid #cbd5e1;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .badge-blue {
        background: linear-gradient(135deg, #3b82f6, #1d4ed8);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-block;
        margin: 0.25rem;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.3);
    }
    
    .badge-light-blue {
        background: linear-gradient(135deg, #0ea5e9, #0284c7);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-block;
        margin: 0.25rem;
        box-shadow: 0 2px 4px rgba(14, 165, 233, 0.3);
    }
    
    .badge-yellow {
        background: linear-gradient(135deg, #f59e0b, #d97706);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-block;
        margin: 0.25rem;
        box-shadow: 0 2px 4px rgba(245, 158, 11, 0.3);
    }
    
    .badge-green {
        background: linear-gradient(135deg, #10b981, #059669);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-block;
        margin: 0.25rem;
        box-shadow: 0 2px 4px rgba(16, 185, 129, 0.3);
    }
    
    .section-title {
        color: #1e293b;
        font-size: 1.2rem;
        font-weight: 700;
        margin: 1.5rem 0 1rem 0;
        border-bottom: 2px solid #e2e8f0;
        padding-bottom: 0.5rem;
    }
    
    .field-label {
        color: #475569;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }
    
    .field-value {
        color: #1e293b;
        font-size: 1rem;
        margin-bottom: 1rem;
    }
    
    .status-yes {
        color: #059669;
        font-weight: 600;
    }
    
    .status-no {
        color: #dc2626;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)


class ASCOmindApp:
    """Main ASCOmind+ Streamlit Application"""
    
    def __init__(self):
        """Initialize the ASCOmind+ application with performance optimizations"""
        
        # Refresh settings to load API keys from Streamlit secrets
        settings.refresh_from_secrets()
        
        # Initialize session state first
        self.initialize_session_state()
        
        # Initialize database and utilities (lightweight operations)
        try:
            self.database = get_database(session_id=getattr(st.session_state, 'session_id', None))
            self.file_processor = FileProcessor()
            self.abstract_extractor = AbstractExtractor()
        except Exception as e:
            st.warning(f"Database initialization issue: {e}")
            self.database = None
            self.file_processor = None
            self.abstract_extractor = None
        
        # Initialize core agents with better error handling (lazy loading)
        try:
            self.metadata_extractor = EnhancedMetadataExtractor()
            self.categorizer = SmartCategorizer()
            self.protocol_maker = ProtocolMaker()
        except Exception as e:
            st.warning(f"Core agents initialization delayed: {e}")
            self.metadata_extractor = None
            self.categorizer = None
            self.protocol_maker = None
        
        # Initialize analyzer only when needed (lazy loading)
        self.analyzer = None
        self.visualizer = None
        
        # Initialize vector store and AI assistant only when needed (lazy loading)
        self.vector_store = None
        self.ai_assistant = None
    
    def initialize_session_state(self):
        """Initialize session state variables with session isolation"""
        
        # Generate or retrieve session ID for data isolation
        if 'session_id' not in st.session_state:
            import uuid
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            random_id = str(uuid.uuid4())[:8]
            st.session_state.session_id = f"session_{timestamp}_{random_id}"
        
        # Developer mode detection
        if 'developer_mode' not in st.session_state:
            # Check URL parameters for ?dev
            query_params = st.query_params
            st.session_state.developer_mode = 'dev' in query_params or query_params.get('dev') == 'true'
        
        # LLM Provider selection (for developer mode)
        if 'selected_llm_provider' not in st.session_state:
            st.session_state.selected_llm_provider = settings.DEFAULT_LLM_PROVIDER
            
        if 'extracted_data' not in st.session_state:
            st.session_state.extracted_data = []
        
        if 'categorization_data' not in st.session_state:
            st.session_state.categorization_data = []
        
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
        
        if 'visualizations' not in st.session_state:
            st.session_state.visualizations = None
        
        if 'session_stats' not in st.session_state:
            st.session_state.session_stats = {
                'total_abstracts': 0,
                'total_processing_time': 0.0,
                'session_start_time': time.time(),
                'abstracts_processed': 0,
                'files_processed': 0,
                'processing_history': []
            }
        
        if 'current_page' not in st.session_state:
            st.session_state.current_page = "Dashboard"
        
        if 'demo_mode' not in st.session_state:
            st.session_state.demo_mode = False
        
        # Vector store and AI assistant session state
        if 'vector_embedding_status' not in st.session_state:
            st.session_state.vector_embedding_status = []
        
        if 'ai_conversation_history' not in st.session_state:
            st.session_state.ai_conversation_history = []
        
        if 'ai_context' not in st.session_state:
            st.session_state.ai_context = {}
        
        # Session isolation flags
        if 'session_data_isolated' not in st.session_state:
            st.session_state.session_data_isolated = True
    
    def run(self):
        """Main application entry point"""
        
        # Enhanced Header with better styling
        st.markdown("""
        <div class="main-header">
            <h1>üß¨ ASCOmind+ Medical Intelligence Platform</h1>
            <p>Advanced Oncology Research Analytics & Clinical Insights Powered by AI</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced sidebar navigation
        with st.sidebar:
            st.markdown("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h2 style="background: linear-gradient(135deg, #667eea, #764ba2); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin: 0;">Navigation</h2>
            </div>
            """, unsafe_allow_html=True)
            
            # Modern navigation with interactive buttons
            st.markdown("""
            <style>
            .nav-button {
                display: block;
                width: 100%;
                padding: 1rem 1.5rem;
                margin-bottom: 0.5rem;
                border: none;
                border-radius: 0.75rem;
                background: linear-gradient(135deg, #f8fafc, #ffffff);
                color: #64748b;
                text-decoration: none;
                font-weight: 500;
                font-size: 0.95rem;
                cursor: pointer;
                transition: all 0.3s ease;
                border: 1px solid #e2e8f0;
                box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1);
            }
            
            .nav-button:hover {
                background: linear-gradient(135deg, #667eea20, #764ba220);
                border-color: #667eea;
                transform: translateY(-1px);
                box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
                color: #1e293b;
            }
            
            .nav-button.active {
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                border-color: #5a67d8;
                box-shadow: 0 4px 6px -1px rgba(102, 126, 234, 0.3);
            }
            
            .nav-button.active:hover {
                background: linear-gradient(135deg, #5a67d8, #6b46c1);
                transform: translateY(-1px);
                box-shadow: 0 6px 8px -1px rgba(102, 126, 234, 0.4);
            }
            
            .nav-icon {
                font-size: 1.25rem;
                margin-right: 0.75rem;
                display: inline-block;
                width: 24px;
                text-align: center;
            }
            
            .nav-text {
                display: inline-block;
                vertical-align: middle;
            }
            
            .nav-badge {
                float: right;
                background: rgba(255, 255, 255, 0.2);
                color: inherit;
                padding: 0.125rem 0.5rem;
                border-radius: 9999px;
                font-size: 0.75rem;
                font-weight: 600;
                margin-left: 0.5rem;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # Navigation options with enhanced design
            nav_options = [
                {"icon": "üè†", "name": "Welcome", "key": "welcome", "badge": None},
                {"icon": "üìä", "name": "Dashboard", "key": "dashboard", "badge": len(st.session_state.extracted_data) if st.session_state.extracted_data else None},
                {"icon": "üìÑ", "name": "Abstract Analysis", "key": "abstract", "badge": len(st.session_state.extracted_data) if st.session_state.extracted_data else None},
                {"icon": "ü§ñ", "name": "AI Assistant", "key": "ai", "badge": len(st.session_state.ai_conversation_history) if len(st.session_state.ai_conversation_history) > 0 else None},
                {"icon": "üî¨", "name": "Protocol Generator", "key": "protocol", "badge": None},
                {"icon": "üîç", "name": "Research Explorer", "key": "research", "badge": "Soon"},
                {"icon": "üíä", "name": "Treatment Intelligence", "key": "treatment", "badge": "Soon"},
                {"icon": "üìà", "name": "Market Analytics", "key": "market", "badge": "Soon"},
                {"icon": "‚öôÔ∏è", "name": "Settings", "key": "settings", "badge": None}
            ]
            
            # Get current page from session state or default to Welcome
            if 'current_nav_page' not in st.session_state:
                st.session_state.current_nav_page = 'welcome'
            
            # Create navigation buttons
            for option in nav_options:
                # Determine if this button is active
                is_active = st.session_state.current_nav_page == option['key']
                
                # Create badge text if badge exists
                badge_text = ''
                if option['badge'] is not None:
                    if isinstance(option['badge'], str):
                        badge_text = f" ({option['badge']})"
                    elif isinstance(option['badge'], int) and option['badge'] > 0:
                        badge_text = f" ({option['badge']})"
                
                # Create button label with icon and badge
                button_label = f"{option['icon']} {option['name']}{badge_text}"
                
                # Use different button types for active vs inactive
                if is_active:
                    st.button(
                        button_label,
                        key=f"nav_btn_{option['key']}",
                        help=f"Current page: {option['name']}",
                        type="primary",
                        use_container_width=True,
                        disabled=True
                    )
                else:
                    if st.button(
                        button_label,
                        key=f"nav_btn_{option['key']}",
                        help=f"Go to {option['name']}",
                        use_container_width=True
                    ):
                        st.session_state.current_nav_page = option['key']
                        st.rerun()
            
            # Add JavaScript for button interactions
            st.markdown("""
            <script>
            function selectPage(pageKey) {
                // This will be handled by the Streamlit button clicks
                console.log('Selected page:', pageKey);
            }
            </script>
            """, unsafe_allow_html=True)
            
            # Enhanced quick stats section
            if st.session_state.extracted_data:
                st.markdown("---")  # Divider
                st.markdown("### üìä Quick Stats")
                
                # Simple stats without complex calculations
                total_studies = len(st.session_state.extracted_data)
                st.metric("üìö Studies", total_studies, help="Total studies processed")
                
                # Show categorization stats if available
                if st.session_state.categorization_data and len(st.session_state.categorization_data) > 0:
                    st.metric("üè∑Ô∏è Categorized", len(st.session_state.categorization_data), help="Studies with AI categorization")
                
                # Simple session timing
                if hasattr(st.session_state, 'session_stats'):
                    session_time = time.time() - st.session_state.session_stats.get('session_start_time', time.time())
                    st.metric("‚è±Ô∏è Session", f"{session_time/60:.1f}m", help="Current session duration")
            
            # Quick action buttons for common tasks
            if st.session_state.extracted_data:
                st.markdown("---")
                st.markdown("### ‚ö° Quick Actions")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üìä Analyze", use_container_width=True, help="Generate analysis"):
                        st.session_state.current_nav_page = 'dashboard'
                        st.rerun()
                with col2:
                    if st.button("ü§ñ Ask AI", use_container_width=True, help="Go to AI Assistant"):
                        st.session_state.current_nav_page = 'ai'
                        st.rerun()
        
        # Route to appropriate page
        page_name = st.session_state.current_nav_page
        if page_name == "welcome":
            self.render_welcome()
        elif page_name == "dashboard":
            self.render_dashboard()
        elif page_name == "abstract":
            self.render_abstract_analyzer()
        elif page_name == "protocol":
            self.render_protocol_generator()
        elif page_name == "research":
            self.render_research_explorer()
        elif page_name == "treatment":
            self.render_treatment_intelligence()
        elif page_name == "market":
            self.render_market_analytics()
        elif page_name == "ai":
            self.render_ai_assistant()
        elif page_name == "settings":
            self.render_settings()
        else:
            # Default to welcome
            st.session_state.current_nav_page = 'welcome'
            self.render_welcome()
    
    def render_welcome(self):
        """Render welcome and getting started page"""
        
        st.markdown("""
        <div class="section-header">
            <h2>üè† Welcome to ASCOmind+</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Main welcome section
        st.markdown("""
        <div class="insight-panel" style="text-align: center; margin-bottom: 2rem;">
            <h3 style="color: #1e293b; margin-bottom: 1rem;">üöÄ Your AI-Powered Medical Research Platform</h3>
            <p style="color: #64748b; font-size: 1.1rem; margin-bottom: 1.5rem;">
                Transform medical abstracts into actionable insights with advanced AI analysis
            </p>
            <div style="background: linear-gradient(135deg, #667eea20, #f093fb20); padding: 1.5rem; border-radius: 0.75rem; display: inline-block;">
                <span style="font-size: 3rem;">üß¨</span>
                <div style="margin-top: 0.5rem; font-weight: 600; color: #1e293b;">Ready to get started?</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Getting started workflow
        st.markdown("""
        <div class="section-header">
            <h3>üéØ Quick Start Guide</h3>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="metric-card" style="text-align: center; height: 200px; display: flex; flex-direction: column; justify-content: center;">
                <div style="font-size: 2.5rem; margin-bottom: 0.75rem;">üìÑ</div>
                <h4 style="margin-bottom: 0.5rem; color: #1e293b;">1. Upload Abstracts</h4>
                <p style="color: #64748b; font-size: 0.9rem; margin: 0;">Upload research papers, abstracts, or text files for AI analysis</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card" style="text-align: center; height: 200px; display: flex; flex-direction: column; justify-content: center;">
                <div style="font-size: 2.5rem; margin-bottom: 0.75rem;">ü§ñ</div>
                <h4 style="margin-bottom: 0.5rem; color: #1e293b;">2. AI Processing</h4>
                <p style="color: #64748b; font-size: 0.9rem; margin: 0;">Automatic extraction of 50+ data elements with intelligent categorization</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card" style="text-align: center; height: 200px; display: flex; flex-direction: column; justify-content: center;">
                <div style="font-size: 2.5rem; margin-bottom: 0.75rem;">üìä</div>
                <h4 style="margin-bottom: 0.5rem; color: #1e293b;">3. View Insights</h4>
                <p style="color: #64748b; font-size: 0.9rem; margin: 0;">Interactive dashboards, AI chat, and comprehensive analytics</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Quick action buttons
        st.markdown("---")
        st.markdown("### ‚ö° Ready to Start?")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìÑ Upload Abstracts", type="primary", use_container_width=True, help="Go to Abstract Analysis to upload your research files"):
                st.session_state.current_nav_page = 'abstract'
                st.rerun()
        
        with col2:
            if st.button("ü§ñ Try AI Assistant", use_container_width=True, help="Chat with our AI research assistant"):
                st.session_state.current_nav_page = 'ai'
                st.rerun()
        
        with col3:
            if st.button("üìä View Demo Dashboard", use_container_width=True, help="See what the dashboard looks like", disabled=not st.session_state.extracted_data):
                if st.session_state.extracted_data:
                    st.session_state.current_nav_page = 'dashboard'
                    st.rerun()
                else:
                    st.info("Upload and process abstracts first to view the dashboard!")
        
        # Platform capabilities
        st.markdown("""
        <div class="section-header" style="margin-top: 2rem;">
            <h3>üåü Platform Capabilities</h3>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="insight-panel">
                <h4 style="color: #1e293b; margin-bottom: 1rem;">üìä Advanced Analytics</h4>
                <ul style="color: #64748b; line-height: 1.6;">
                    <li>‚úÖ 50+ data elements extracted automatically</li>
                    <li>‚úÖ Study categorization and classification</li>
                    <li>‚úÖ Efficacy and safety analysis</li>
                    <li>‚úÖ Treatment landscape mapping</li>
                    <li>‚úÖ Publication-quality visualizations</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="insight-panel">
                <h4 style="color: #1e293b; margin-bottom: 1rem;">ü§ñ AI-Powered Features</h4>
                <ul style="color: #64748b; line-height: 1.6;">
                    <li>üß† Intelligent research assistant</li>
                    <li>üîç Semantic search across studies</li>
                    <li>üìù Automated protocol generation</li>
                    <li>üí° Clinical insights and recommendations</li>
                    <li>‚ö° Real-time question answering</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        # Current session status
        if st.session_state.extracted_data:
            st.markdown("---")
            st.markdown("### üìà Your Current Session")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üìö Studies Processed", len(st.session_state.extracted_data))
            with col2:
                total_patients = sum(d.patient_demographics.total_enrolled for d in st.session_state.extracted_data if d.patient_demographics.total_enrolled)
                st.metric("üë• Total Patients", f"{total_patients:,}" if total_patients else "N/A")
            with col3:
                ai_conversations = len(st.session_state.ai_conversation_history)
                st.metric("üí¨ AI Conversations", ai_conversations)
            with col4:
                if hasattr(st.session_state, 'session_stats'):
                    session_time = time.time() - st.session_state.session_stats.get('session_start_time', time.time())
                    st.metric("‚è±Ô∏è Session Time", f"{session_time/60:.1f}m")
                else:
                    st.metric("‚è±Ô∏è Session Time", "0m")
            
            # Continue working buttons
            st.markdown("### üöÄ Continue Your Analysis")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üìä View Dashboard", type="primary", use_container_width=True):
                    st.session_state.current_nav_page = 'dashboard'
                    st.rerun()
            with col2:
                if st.button("üìÑ Add More Studies", use_container_width=True):
                    st.session_state.current_nav_page = 'abstract'
                    st.rerun()
            with col3:
                if st.button("ü§ñ Ask AI Questions", use_container_width=True):
                    st.session_state.current_nav_page = 'ai'
                    st.rerun()
    
    def render_dashboard(self):
        """Render enhanced main dashboard with modern UI - Data visualization focused"""
        
        st.markdown("""
        <div class="section-header">
            <h2>üìä Executive Dashboard</h2>
        </div>
        """, unsafe_allow_html=True)
        
        if not st.session_state.extracted_data:
            # Simple message directing users to upload data
            st.markdown("""
            <div class="insight-panel" style="text-align: center; margin-bottom: 2rem;">
                <h3 style="color: #1e293b; margin-bottom: 1rem;">üìä No Data Available</h3>
                <p style="color: #64748b; font-size: 1.1rem; margin-bottom: 1.5rem;">
                    Upload and process abstracts to view interactive analytics and insights
                </p>
                <div style="margin-top: 1.5rem;">
            """, unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìÑ Go to Abstract Analysis", type="primary", use_container_width=True):
                    st.session_state.current_nav_page = 'abstract'
                    st.rerun()
            with col2:
                if st.button("üè† Back to Welcome", use_container_width=True):
                    st.session_state.current_nav_page = 'welcome'
                    st.rerun()
            
            st.markdown("</div></div>", unsafe_allow_html=True)
            return
        
        # Generate analysis if not available
        if not st.session_state.analysis_results:
            with st.spinner("üß† Generating comprehensive analysis..."):
                analyzer = self._get_analyzer()
                st.session_state.analysis_results = analyzer.analyze_comprehensive_dataset(
                    st.session_state.extracted_data
                )
        
        # Generate visualizations if not available
        if not st.session_state.visualizations:
            with st.spinner("üé® Creating interactive visualizations..."):
                visualizer = self._get_visualizer()
                st.session_state.visualizations = visualizer.create_comprehensive_dashboard(
                    st.session_state.extracted_data  # Use extracted_data instead of analysis_results
                )
        
        # Display enhanced dashboard content
        self._render_dashboard_content()
    
    def _render_dashboard_content(self):
        """Render enhanced dashboard content with modern visualizations"""
        
        # Enhanced key metrics row with modern styling
        st.markdown("""
        <div class="section-header">
            <h3>üìà Key Performance Indicators</h3>
        </div>
        """, unsafe_allow_html=True)
        
        summary_stats = st.session_state.analysis_results.get('dataset_overview', {}).get('summary_statistics', {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_studies = summary_stats.get('total_studies', len(st.session_state.extracted_data))
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 1.5rem; border-radius: 1rem; text-align: center; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
                <div style="font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem;">{total_studies}</div>
                <div style="font-size: 0.875rem; opacity: 0.9;">Studies Analyzed</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            randomized_count = sum(1 for data in st.session_state.extracted_data if data.study_design.randomized)
            randomized_pct = (randomized_count / total_studies * 100) if total_studies > 0 else 0
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #f59e0b, #fbbf24); color: white; padding: 1.5rem; border-radius: 1rem; text-align: center; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
                <div style="font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem;">{randomized_pct:.1f}%</div>
                <div style="font-size: 0.875rem; opacity: 0.9;">Randomized Studies</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            total_enrollment = sum(data.patient_demographics.total_enrolled for data in st.session_state.extracted_data if data.patient_demographics.total_enrolled)
            enrollment_display = f"{total_enrollment:,}" if total_enrollment > 0 else "N/A"
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #10b981, #10b981dd); color: white; padding: 1.5rem; border-radius: 1rem; text-align: center; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
                <div style="font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem;">{enrollment_display}</div>
                <div style="font-size: 0.875rem; opacity: 0.9;">Total Patients</div>
            </div>
            """, unsafe_allow_html=True)
        
        # Simple, data-driven visualizations based on extracted studies only
        st.markdown("""
        <div class="section-header" style="margin-top: 2rem;">
            <h3>üìä Your Study Data Analysis</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Extract actual data from user's studies
        study_data = []
        for i, data in enumerate(st.session_state.extracted_data):
            categorization = st.session_state.categorization_data[i] if i < len(st.session_state.categorization_data) else {}
            
            # Get study info
            study_name = data.study_identification.study_acronym or f"Study {i+1}"
            study_title = data.study_identification.title[:50] + "..." if len(data.study_identification.title) > 50 else data.study_identification.title
            
            # Extract ORR
            orr_val = None
            orr_data = data.efficacy_outcomes.overall_response_rate
            if orr_data and isinstance(orr_data, dict):
                orr_val = orr_data.get('value')
                if orr_val is not None:
                    try:
                        orr_val = float(orr_val)
                    except:
                        orr_val = None
            
            # Extract PFS
            pfs_val = None
            pfs_data = data.efficacy_outcomes.progression_free_survival
            if pfs_data and isinstance(pfs_data, dict):
                pfs_val = pfs_data.get('median')
                if pfs_val is not None:
                    try:
                        pfs_val = float(pfs_val)
                    except:
                        pfs_val = None
            
            # Extract enrollment
            enrollment = data.patient_demographics.total_enrolled
            
            study_data.append({
                'name': study_name,
                'title': study_title,
                'phase': data.study_design.study_type.value,
                'category': categorization.get('study_category', 'Unknown'),
                'orr': orr_val,
                'pfs': pfs_val,
                'enrollment': enrollment,
                'confidence': data.extraction_confidence
            })
        
        # Only show visualizations if we have actual data
        if len(study_data) == 1:
            # Single study view
            study = study_data[0]
            st.markdown(f"### üìã Analysis of: {study['name']}")
            st.markdown(f"**Title:** {study['title']}")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                orr_display = f"{study['orr']:.1f}%" if study['orr'] is not None else "N/A"
                st.metric("üéØ ORR", orr_display)
            with col2:
                pfs_display = f"{study['pfs']:.1f} mo" if study['pfs'] is not None else "N/A"
                st.metric("üìà PFS", pfs_display)
            with col3:
                enroll_display = str(study['enrollment']) if study['enrollment'] else "N/A"
                st.metric("üë• Enrolled", enroll_display)
            with col4:
                st.metric("‚úÖ Quality", f"{study['confidence']:.0%}")
            
            # Show what data was actually found
            st.markdown("#### üìä Data Availability")
            data_found = []
            if study['orr'] is not None:
                data_found.append(f"‚úÖ Response Rate: {study['orr']:.1f}%")
            if study['pfs'] is not None:
                data_found.append(f"‚úÖ PFS: {study['pfs']:.1f} months")
            if study['enrollment']:
                data_found.append(f"‚úÖ Enrollment: {study['enrollment']} patients")
            
            if data_found:
                for item in data_found:
                    st.markdown(item)
            else:
                st.info("‚ÑπÔ∏è Limited quantitative data available in this abstract")
        
        elif len(study_data) > 1:
            # Multiple studies comparison
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üéØ Response Rates")
                
                # Only show studies with ORR data
                studies_with_orr = [s for s in study_data if s['orr'] is not None]
                
                if studies_with_orr:
                    fig_orr = go.Figure(data=[
                        go.Bar(
                            x=[s['name'] for s in studies_with_orr],
                            y=[s['orr'] for s in studies_with_orr],
                            marker_color=['#667eea', '#10b981', '#f59e0b', '#ef4444', '#8b5cf6'][:len(studies_with_orr)],
                            text=[f"{s['orr']:.1f}%" for s in studies_with_orr],
                            textposition='auto',
                        )
                    ])
                    
                    fig_orr.update_layout(
                        title="Your Studies: Overall Response Rate",
                        xaxis_title="Study",
                        yaxis_title="ORR (%)",
                        height=400,
                        showlegend=False,
                        template="plotly_white"
                    )
                    
                    st.plotly_chart(fig_orr, use_container_width=True)
                else:
                    st.info("üìä No ORR data available in your studies")
            
            with col2:
                st.markdown("#### üë• Study Sizes")
                
                # Only show studies with enrollment data
                studies_with_enrollment = [s for s in study_data if s['enrollment']]
                
                if studies_with_enrollment:
                    fig_enroll = go.Figure(data=[
                        go.Scatter(
                            x=[s['name'] for s in studies_with_enrollment],
                            y=[s['enrollment'] for s in studies_with_enrollment],
                            mode='markers+text',
                            marker=dict(
                                size=[max(20, min(60, s['enrollment']/20)) for s in studies_with_enrollment],
                                color=['#667eea', '#10b981', '#f59e0b', '#ef4444', '#8b5cf6'][:len(studies_with_enrollment)],
                                opacity=0.7
                            ),
                            text=[str(s['enrollment']) for s in studies_with_enrollment],
                            textposition="middle center",
                            textfont=dict(color="white", size=12, family="Arial Black")
                        )
                    ])
                    
                    fig_enroll.update_layout(
                        title="Your Studies: Patient Enrollment",
                        xaxis_title="Study",
                        yaxis_title="Patients Enrolled",
                        height=400,
                        showlegend=False,
                        template="plotly_white"
                    )
                    
                    st.plotly_chart(fig_enroll, use_container_width=True)
                else:
                    st.info("üìä No enrollment data available in your studies")
            
            # Summary table with actual data
            # st.markdown("#### üìã Study Comparison")
            # summary_table_data = []
            # for study in study_data:
            #     summary_table_data.append({
            #         'Study': study['name'],
            #         'Phase': study['phase'],
            #         'Category': study['category'],
            #         'Patients (N)': study['enrollment'] if study['enrollment'] else 'N/A',
            #         'ORR (%)': f"{study['orr']:.1f}" if study['orr'] is not None else 'N/A',
            #         'PFS (months)': f"{study['pfs']:.1f}" if study['pfs'] is not None else 'N/A',
            #         'Data Quality': f"{study['confidence']:.0%}"
            #     })
            
            # summary_df = pd.DataFrame(summary_table_data)
            # st.dataframe(summary_df, use_container_width=True, hide_index=True)
            
            # --- NEW: Treatment Distribution Table ---
            st.markdown("---")
            if len(study_data) >= 2:  # Show distribution table for 2+ studies
                distribution_data = self._generate_treatment_distribution_table()
                self._display_treatment_distribution_table(distribution_data)
            
            # --- NEW: High-Risk Population Analysis ---
            st.markdown("---")
            high_risk_data = self._generate_high_risk_population_analysis()
            self._display_high_risk_population_analysis(high_risk_data)
        
        else:
            st.info("üìä No studies available. Upload abstracts to see visualizations.")
        
        # Show data extraction summary
        st.markdown("#### üìà Extraction Summary")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            studies_with_orr = len([s for s in study_data if s['orr'] is not None])
            st.metric("üéØ Studies with ORR", f"{studies_with_orr}/{len(study_data)}")
        
        with col2:
            studies_with_pfs = len([s for s in study_data if s['pfs'] is not None])
            st.metric("üìà Studies with PFS", f"{studies_with_pfs}/{len(study_data)}")
        
        with col3:
            studies_with_enrollment = len([s for s in study_data if s['enrollment']])
            st.metric("üë• Studies with Enrollment", f"{studies_with_enrollment}/{len(study_data)}")
    
        # Show all visualizer plots (skip empty/placeholder plots)
        if st.session_state.visualizations:
            with st.expander('üìä Advanced Visualizations (AI Visualizer)', expanded=True):
                for viz_name, fig in st.session_state.visualizations.items():
                    # Skip if figure has no data traces (placeholder)
                    if hasattr(fig, 'data') and len(fig.data) == 0:
                        continue
                    st.markdown(f"#### {viz_name.replace('_', ' ').title()}")
                    st.plotly_chart(fig, use_container_width=True)
    
        # --- NEW: Analyzer-based advanced visualizations ---
        analyzer_results = st.session_state.analysis_results
        from agents.visualizer import AdvancedVisualizer
        adv_viz = AdvancedVisualizer()
        with st.expander('ü§ñ AI Advanced Analytics (Analyzer Results)', expanded=False):
            # Efficacy Benchmarks
            efficacy_benchmarks = analyzer_results.get('efficacy_benchmarks', {})
            if efficacy_benchmarks:
                st.markdown('#### Efficacy Benchmarks by Line of Therapy')
                fig = adv_viz._create_efficacy_analysis_chart_from_analyzer(efficacy_benchmarks)
                st.plotly_chart(fig, use_container_width=True)
            # Safety Patterns
            safety_patterns = analyzer_results.get('safety_patterns', {})
            if safety_patterns:
                st.markdown('#### Safety Patterns by Line of Therapy')
                fig = adv_viz._create_safety_analysis_chart_from_analyzer(safety_patterns)
                st.plotly_chart(fig, use_container_width=True)
    
    def render_abstract_analyzer(self):
        """Enhanced abstract analysis interface with comprehensive features"""
        
        # Developer mode indicator (for debugging)
        if st.session_state.developer_mode:
            st.info("üîß **Developer Mode Active** - Advanced processing options available")
        
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <h2 style="background: linear-gradient(135deg, #667eea, #764ba2); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">üìÑ Abstract Analysis & Processing</h2>
            <p style="color: #64748b; font-size: 1.1rem;">Extract comprehensive insights from clinical abstracts using advanced AI analysis</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced upload section with modern design
        st.markdown("""
        <div class="section-header">
            <h3>üì§ Upload Medical Abstracts</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Modern upload method selector
        upload_method = st.radio(
            "Choose upload method:",
            ["üìù Text Input", "üìÅ File Upload", "üìã Batch Upload"],
            horizontal=True,
            help="Select how you want to input your abstracts for analysis"
        )
        
        if upload_method == "üìù Text Input":
            self._render_text_input()
        elif upload_method == "üìÅ File Upload":
            self._render_file_upload()
        elif upload_method == "üìã Batch Upload":
            self._render_batch_upload()
        
        # Display extracted data with enhanced UI
        if st.session_state.extracted_data:
            # Enhanced session statistics header
            session_summary = self._get_session_summary()
            
            st.markdown("""
            <div class="section-header" style="margin-top: 2rem;">
                <h3>üìä Session Summary</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Modern performance metrics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 1.25rem; border-radius: 0.75rem; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <div style="font-size: 1.75rem; font-weight: 700; margin-bottom: 0.25rem;">{len(st.session_state.extracted_data)}</div>
                    <div style="font-size: 0.75rem; opacity: 0.9;">üìä Studies</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                total_processing_time = session_summary['total_processing_time']
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #10b981, #34d399); color: white; padding: 1.25rem; border-radius: 0.75rem; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <div style="font-size: 1.75rem; font-weight: 700; margin-bottom: 0.25rem;">{total_processing_time:.1f}s</div>
                    <div style="font-size: 0.75rem; opacity: 0.9;">‚ö° Processing</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                avg_time = session_summary['avg_time_per_abstract']
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #f59e0b, #fbbf24); color: white; padding: 1.25rem; border-radius: 0.75rem; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <div style="font-size: 1.75rem; font-weight: 700; margin-bottom: 0.25rem;">{avg_time:.1f}s</div>
                    <div style="font-size: 0.75rem; opacity: 0.9;">üìä Avg/Study</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #8b5cf6, #a78bfa); color: white; padding: 1.25rem; border-radius: 0.75rem; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    <div style="font-size: 1.75rem; font-weight: 700; margin-bottom: 0.25rem;">{session_summary['session_duration']:.0f}s</div>
                    <div style="font-size: 0.75rem; opacity: 0.9;">üïí Session</div>
                </div>
                """, unsafe_allow_html=True)
            
            # Enhanced data summary table
            st.markdown("""
            <div class="section-header" style="margin-top: 2rem;">
                <h3>üìã Extracted Data Summary</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Create enhanced summary table with modern styling
            summary_data = []
            for i, data in enumerate(st.session_state.extracted_data):
                # Get categorization data if available
                categorization = st.session_state.categorization_data[i] if i < len(st.session_state.categorization_data) else {}
                
                # Get additional data points
                nct_number = data.study_identification.nct_number or "N/A"
                study_acronym = data.study_identification.study_acronym or ""
                title_display = f"{study_acronym} - {data.study_identification.title[:40]}..." if study_acronym else (data.study_identification.title[:50] + "..." if len(data.study_identification.title) > 50 else data.study_identification.title)
                
                # Get efficacy data
                orr_value = self._extract_orr(data)
                pfs_data = self._extract_pfs(data)
                median_age = data.patient_demographics.median_age or "N/A"
                
                # Get study category
                study_category = categorization.get('study_category', 'Unknown')
                
                # Enhanced quality badge with HTML
                quality_badge = self._get_enhanced_quality_badge(data.extraction_confidence)
                
                summary_data.append({
                    'üìÑ Title': title_display,
                    'üî¨ NCT#': nct_number,
                    'üè• Study Type': data.study_design.study_type.value,
                    'üè∑Ô∏è Category': study_category,
                    'üë• N': data.patient_demographics.total_enrolled or "N/A",
                    'üìä Age': f"{median_age}" if median_age != "N/A" else "N/A",
                    'üéØ ORR (%)': orr_value,
                    'üìà PFS (mo)': pfs_data,
                    '‚è∞ Extracted': data.extraction_timestamp.strftime("%H:%M:%S")
                })
            
            df = pd.DataFrame(summary_data)
            
            # Custom dataframe display with enhanced styling
            st.markdown("""
            <style>
                .stDataFrame table {
                    background: white;
                    border-radius: 0.75rem;
                    overflow: hidden;
                    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
                    border: 1px solid #e2e8f0;
                }
                .stDataFrame th {
                    background: linear-gradient(135deg, #667eea, #764ba2) !important;
                    color: white !important;
                    font-weight: 600 !important;
                    text-align: center !important;
                    padding: 1rem !important;
                }
                .stDataFrame td {
                    padding: 0.75rem !important;
                    border-bottom: 1px solid #f1f5f9 !important;
                    text-align: center !important;
                    vertical-align: middle !important;
                }
                .stDataFrame tr:hover {
                    background-color: #f8fafc !important;
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.dataframe(df, use_container_width=True, hide_index=True)
            
            # Developer mode toggle for technical explanations
            show_dev_explanations = st.checkbox("üîß Show Developer Information", value=False, help="Show technical details about scoring and metrics")
            
            if show_dev_explanations:
                with st.expander("‚ÑπÔ∏è Developer: Scoring System Details", expanded=False):
                    st.markdown("""
                    ### üéØ **Technical Scoring System Information**
                    
                    **Quality Assessment Algorithm:**
                    - Uses LLM's internal confidence scores (highly calibrated)
                    - Success-based scoring: counts successful extractions vs attempts
                    - No penalties for missing data that wasn't in source abstract
                    - Quality reflects extraction accuracy, not schema completeness
                    
                    **Quality Thresholds:**
                    - üèÜ **Excellent (80%+)**: High LLM confidence in extraction accuracy
                    - ‚úÖ **Good (60-80%)**: Solid LLM confidence with good data extraction
                    - ‚ö†Ô∏è **Fair (40-60%)**: Moderate LLM confidence, may need review
                    - ‚ùå **Poor (<40%)**: Low LLM confidence, requires attention
                    
                    **Efficiency Calculation (if enabled):**
                    - Baseline: 6 seconds per abstract (includes API latency)
                    - Quality bonus: up to 20% boost for high-confidence extractions
                    - Realistic thresholds: 60%+ excellent, 40-60% good, <40% needs optimization
                    
                    **Current Session Metrics:**
                    """)
                    
                    # Show technical session details in developer mode
                    session_summary = self._get_session_summary()
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown(f"""
                        **Processing Efficiency:** {session_summary['processing_efficiency']:.1f}%  
                        **Quality Bonus Applied:** {max(0, (sum(d.extraction_confidence for d in st.session_state.extracted_data) / len(st.session_state.extracted_data) - 0.6) * 50):.1f}%
                        """)
                    
                    with col2:
                        avg_confidence = sum(d.extraction_confidence for d in st.session_state.extracted_data) / len(st.session_state.extracted_data)
                        st.markdown(f"""
                        **Average LLM Confidence:** {avg_confidence:.1%}  
                        **Confidence Range:** {min(d.extraction_confidence for d in st.session_state.extracted_data):.1%} - {max(d.extraction_confidence for d in st.session_state.extracted_data):.1%}
                        """)
                    
                    with col3:
                        st.markdown(f"""
                        **API Response Time:** {session_summary['avg_time_per_abstract']:.1f}s avg  
                        **Processing Overhead:** {session_summary['total_processing_time'] - (session_summary['abstracts_processed'] * 6):.1f}s total
                        """)
            
            # Enhanced detailed data view
            st.markdown("""
            <div class="section-header" style="margin-top: 2rem;">
                <h3>üîç Detailed Extraction Results</h3>
            </div>
            """, unsafe_allow_html=True)
            
            for i, data in enumerate(st.session_state.extracted_data):
                # Get categorization data if available
                categorization = st.session_state.categorization_data[i] if i < len(st.session_state.categorization_data) else {}
                
                with st.expander(f"üìã Study {i+1}: {data.study_identification.study_acronym or 'Study'} - {data.study_identification.title[:60]}...", expanded=False):
                    
                    # Use the new tabbed interface for each individual study
                    self._show_individual_study_tabs(data, categorization, i)
            
            # Enhanced Export and Action options
            st.markdown("""
            <div class="section-header" style="margin-top: 2rem;">
                <h3>‚ö° Actions & Export</h3>
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üìä Generate Analysis", type="primary", help="Generate comprehensive clinical analysis"):
                    with st.spinner("üß† Generating comprehensive clinical analysis..."):
                        try:
                            # Get analyzer using lazy loading
                            analyzer = self._get_analyzer()
                            
                            # Generate comprehensive analysis
                            st.session_state.analysis_results = analyzer.analyze_comprehensive_dataset(
                                st.session_state.extracted_data
                            )
                            
                            # Generate visualizations using lazy loading
                            visualizer = self._get_visualizer()
                            
                            st.session_state.visualizations = visualizer.create_comprehensive_dashboard(
                                st.session_state.extracted_data  # Use extracted_data instead of analysis_results
                            )
                            
                            st.success("‚úÖ Analysis completed! Check the insights in the Dashboard.")
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"‚ùå Analysis failed: {str(e)}")
                            # Fallback: Generate basic summary
                            st.session_state.analysis_results = self._generate_basic_analysis()
                            st.rerun()
            
            with col2:
                if st.button("üì• Export Data", help="Export extracted data to CSV"):
                    self._export_data()
            
            with col3:
                if st.button("üóëÔ∏è Clear Data", help="Clear all extracted data"):
                    if st.session_state.extracted_data:
                        st.session_state.extracted_data = []
                        st.session_state.categorization_data = []
                        st.session_state.analysis_results = None
                        st.session_state.visualizations = {}
                        st.session_state.session_stats = {
                            'total_processing_time': 0.0,
                            'abstracts_processed': 0,
                            'session_start_time': time.time(),
                            'processing_history': []
                        }
                        st.success("üóëÔ∏è All data cleared successfully!")
                        st.rerun()
    
    def _render_text_input(self):
        """Render text input interface with timing and progress"""
        
        abstract_text = st.text_area(
            "Paste abstract text:",
            height=200,
            placeholder="Enter multiple myeloma research abstract text here..."
        )
        
        if abstract_text and st.button("üîç Process Abstract", type="primary"):
            # Start timing
            start_time = time.time()
            
            # Create progress containers
            progress_container = st.container()
            time_container = st.container()
            
            with progress_container:
                st.subheader("üîÑ Processing Abstract")
                progress_bar = st.progress(0, text="Initializing...")
                status_text = st.empty()
            
            try:
                # Step 1: Extract metadata (30% of progress)
                status_text.text("üß† Extracting metadata with AI...")
                progress_bar.progress(15, text="Extracting metadata...")
                
                extracted_data = asyncio.run(
                    self.metadata_extractor.extract_comprehensive_metadata(abstract_text)
                )
                progress_bar.progress(30, text="Metadata extraction complete")
                
                # Step 2: Categorize study (20% of progress)
                status_text.text("üè∑Ô∏è Categorizing study...")
                progress_bar.progress(40, text="Categorizing study...")
                
                categorization = asyncio.run(
                    self.categorizer.categorize_study(
                        abstract_text, 
                        extracted_data.model_dump()
                    )
                )
                progress_bar.progress(50, text="Study categorization complete")
                
                # Step 3: Embed to vector store (30% of progress)
                embedding_status = None
                if self._get_vector_store():
                    status_text.text("üîó Embedding to knowledge base...")
                    progress_bar.progress(60, text="Creating vector embeddings...")
                    
                    try:
                        embedding_result = asyncio.run(
                            self._get_vector_store().embed_abstract(extracted_data)
                        )
                        progress_bar.progress(80, text="Vector embedding complete")
                        embedding_status = embedding_result
                        
                        # Store embedding status
                        st.session_state.vector_embedding_status[extracted_data.abstract_id] = embedding_result
                        
                    except Exception as e:
                        st.warning(f"Vector embedding failed: {e}")
                        embedding_status = {"status": "error", "reason": str(e)}
                
                # Step 4: Store results (20% of progress)
                status_text.text("üíæ Storing results...")
                progress_bar.progress(90, text="Storing results...")
                
                # Store extracted data
                extracted_data.source_text = abstract_text
                st.session_state.extracted_data.append(extracted_data)
                st.session_state.categorization_data.append(categorization)
                
                # Calculate processing time
                end_time = time.time()
                processing_time = end_time - start_time
                
                progress_bar.progress(100, text="Processing complete!")
                
                # Display completion message with timing and embedding status
                with time_container:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("‚úÖ Status", "Complete")
                    with col2:
                        st.metric("‚è±Ô∏è Processing Time", f"{processing_time:.1f}s")
                    with col3:
                        st.metric("üìä Data Elements", "50+")
                    with col4:
                        if embedding_status:
                            if embedding_status["status"] == "success":
                                st.metric("üîó Vector Status", "‚úÖ Embedded")
                            elif embedding_status["status"] == "skipped":
                                st.metric("üîó Vector Status", "‚è≠Ô∏è Exists")
                            else:
                                st.metric("üîó Vector Status", "‚ùå Failed")
                        else:
                            st.metric("üîó Vector Status", "‚ûñ Disabled")
                
                success_message = f"üéâ Abstract processed successfully in {processing_time:.1f} seconds!"
                if embedding_status and embedding_status["status"] == "success":
                    success_message += f" Created {embedding_status.get('vectors_created', 0)} vector embeddings for AI assistant."
                elif embedding_status and embedding_status["status"] == "skipped":
                    success_message += " Abstract already exists in knowledge base."
                
                st.success(success_message)
                
                # Clear progress after 1 second
                time.sleep(1)
                progress_container.empty()
                
                # Update session statistics
                self._update_session_stats(processing_time, 1)
                
            except Exception as e:
                progress_bar.progress(100, text="‚ùå Processing failed")
                st.error(f"‚ùå Processing failed: {str(e)}")
                
                # Calculate time even on failure
                end_time = time.time()
                processing_time = end_time - start_time
                with time_container:
                    st.metric("‚è±Ô∏è Time Elapsed", f"{processing_time:.1f}s")
    
    def _render_file_upload(self):
        """Render file upload interface with vector embedding integration"""
        
        st.markdown("""
        <div class="section-header">
            <h3>üìÅ Single File Analysis</h3>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "Upload a medical research file",
            type=["pdf", "docx", "txt"],
            help="Supported formats: PDF, Word documents, and text files"
        )
        
        if uploaded_file:
            # File details
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("File Name", uploaded_file.name)
            with col2:
                st.metric("File Size", f"{uploaded_file.size / 1024:.1f} KB")
            with col3:
                st.metric("File Type", uploaded_file.type)
            
            # Processing options (Developer mode only)
            if st.session_state.developer_mode:
                with st.expander("‚öôÔ∏è Processing Options", expanded=True):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        extract_metadata = st.checkbox("üìä Extract Metadata", value=True, help="Extract comprehensive study metadata")
                        categorize_study = st.checkbox("üè∑Ô∏è Categorize Study", value=True, help="Intelligent study categorization")
                        embed_vectors = st.checkbox("üß† Vector Embedding", value=True, help="Create vector embeddings for AI search")
                    
                    with col2:
                        confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.7, 0.1, help="Minimum confidence for extracted data")
                        auto_correct = st.checkbox("üîß Auto-correction", value=True, help="Automatically correct obvious errors")
            else:
                # Default values when developer mode is off
                extract_metadata = True
                categorize_study = True
                embed_vectors = True
                confidence_threshold = 0.7
                auto_correct = True
            
            # Process button
            if st.button("üöÄ Process File", type="primary", use_container_width=True):
                # Initialize processing tracking
                start_time = time.time()
                processing_results = {
                    'metadata_extraction': {'status': 'pending', 'data': None},
                    'categorization': {'status': 'pending', 'data': None}, 
                    'vector_embedding': {'status': 'pending', 'data': None}
                }
                
                # Create progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                step_details = st.empty()
                
                try:
                    # Step 1: Text Extraction (10%)
                    status_text.text("üìÑ Extracting text from file...")
                    progress_bar.progress(10)
                    
                    # Extract text
                    file_content = uploaded_file.read()
                    if uploaded_file.type == "application/pdf":
                        from utils.file_processors import FileProcessor
                        processor = FileProcessor()
                        text_content = processor.process_file(file_content, uploaded_file.name)
                    else:
                        # Handle other file types
                        text_content = file_content.decode('utf-8')
                    
                    if not text_content.strip():
                        st.error("‚ùå Could not extract text from the file.")
                        return
                    
                    # Step 2: Metadata Extraction (30%)
                    if extract_metadata:
                        status_text.text("üîç Extracting comprehensive metadata...")
                        progress_bar.progress(30)
                        
                        try:
                            extracted_data = asyncio.run(
                                self.metadata_extractor.extract_comprehensive_metadata(text_content)
                            )
                            extracted_data.source_file = uploaded_file.name
                            
                            processing_results['metadata_extraction'] = {
                                'status': 'success',
                                'data': extracted_data
                            }
                            step_details.success("‚úÖ Metadata extraction completed")
                        except Exception as e:
                            processing_results['metadata_extraction'] = {
                                'status': 'failed',
                                'error': str(e)
                            }
                            step_details.error(f"‚ùå Metadata extraction failed: {str(e)}")
                    
                    # Step 3: Categorization (50%)
                    if categorize_study and processing_results['metadata_extraction']['status'] == 'success':
                        status_text.text("üè∑Ô∏è Categorizing study...")
                        progress_bar.progress(50)
                        
                        try:
                            category_data = asyncio.run(
                                self.categorizer.categorize_study(
                                    text_content,  # Pass text content, not metadata object
                                    processing_results['metadata_extraction']['data'].model_dump()
                                )
                            )
                            processing_results['categorization'] = {
                                'status': 'success',
                                'data': category_data
                            }
                            step_details.success("‚úÖ Study categorization completed")
                        except Exception as e:
                            processing_results['categorization'] = {
                                'status': 'failed',
                                'error': str(e)
                            }
                            step_details.error(f"‚ùå Categorization failed: {str(e)}")
                    
                    # Step 4: Vector Embedding (80%)
                    if embed_vectors and processing_results['metadata_extraction']['status'] == 'success' and self._get_vector_store():
                        status_text.text("üß† Creating vector embeddings...")
                        progress_bar.progress(80)
                        
                        try:
                            embedding_result = asyncio.run(
                                self._get_vector_store().embed_abstract(processing_results['metadata_extraction']['data'])
                            )
                            processing_results['vector_embedding'] = {
                                'status': 'success',
                                'data': embedding_result
                            }
                            
                            # Update session state for vector embedding status
                            if 'vector_embedding_status' not in st.session_state:
                                st.session_state.vector_embedding_status = []
                            
                            st.session_state.vector_embedding_status.append({
                                'file': uploaded_file.name,
                                'status': embedding_result['status'],
                                'timestamp': datetime.now().isoformat()
                            })
                            
                            if embedding_result['status'] == 'success':
                                step_details.success(f"‚úÖ Vector embedding completed - {embedding_result['vectors_created']} chunks created")
                            elif embedding_result['status'] == 'skipped':
                                step_details.info(f"‚ÑπÔ∏è Vector embedding skipped - {embedding_result['reason']}")
                            else:
                                step_details.warning(f"‚ö†Ô∏è Vector embedding failed - {embedding_result.get('reason', 'Unknown error')}")
                        
                        except Exception as e:
                            processing_results['vector_embedding'] = {
                                'status': 'failed',
                                'error': str(e)
                            }
                            step_details.error(f"‚ùå Vector embedding failed: {str(e)}")
                    
                    # Step 5: Finalization (100%)
                    status_text.text("‚úÖ Processing complete!")
                    progress_bar.progress(100)
                    
                    # Calculate processing time
                    processing_time = time.time() - start_time
                    
                    # Store results in session state
                    if processing_results['metadata_extraction']['status'] == 'success':
                        if 'extracted_data' not in st.session_state:
                            st.session_state.extracted_data = []
                        
                        # Add file metadata
                        extracted_data = processing_results['metadata_extraction']['data']
                        extracted_data.source_file = uploaded_file.name
                        
                        st.session_state.extracted_data.append(extracted_data)
                        
                        # Update session statistics
                        self._update_session_stats(processing_time, 1)
                    
                    # Clear progress indicators
                    progress_bar.empty()
                    status_text.empty()
                    step_details.empty()
                    
                    # Show detailed results
                    self._show_processing_results(processing_results, processing_time)
                    
                    # Success message with summary
                    success_parts = []
                    if processing_results['metadata_extraction']['status'] == 'success':
                        success_parts.append("metadata extracted")
                    if processing_results['categorization']['status'] == 'success':
                        success_parts.append("study categorized")
                    if processing_results['vector_embedding']['status'] == 'success':
                        success_parts.append("vectors created")
                    elif processing_results['vector_embedding']['status'] == 'skipped':
                        success_parts.append("vectors skipped (duplicate)")
                    
                    st.success(f"üéâ **File processed successfully!** {', '.join(success_parts).capitalize()}")
                    
                    # Auto-rerun to refresh the interface
                    st.rerun()
                    
                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    step_details.empty()
                    st.error(f"‚ùå **Processing failed:** {str(e)}")
                    st.info("Please check the file format and try again.")
    
    def _render_batch_upload(self):
        """Render enhanced batch upload interface for processing multiple abstracts via text or files"""
        
        st.markdown("""
        <div class="section-header">
            <h3>üìã Batch Upload Analysis</h3>
        </div>
        """, unsafe_allow_html=True)
        
        st.info("üöÄ **Batch Processing**: Process multiple abstracts efficiently via text input or file uploads")
        
        # Create tabs for different input methods
        text_tab, file_tab = st.tabs(["üìù Text Input", "üìÅ File Upload"])
        
        # Initialize variables
        abstracts = []
        source_info = []
        
        with text_tab:
            st.markdown("**Paste multiple abstracts separated by delimiters:**")
            
            # Text area for multiple abstracts
            batch_text = st.text_area(
                "Abstract content:",
                height=250,
                placeholder="Abstract 1: Title of first study...\n\nAbstract 2: Title of second study...\n\n---\n\nAbstract 3: Title of third study...",
                help="Separate each abstract with blank lines, '---', or use clear delimiters"
            )
            
            # Delimiter options
            col1, col2 = st.columns(2)
            with col1:
                delimiter_type = st.selectbox(
                    "Abstract separator:",
                    ["Auto-detect", "Blank lines", "Triple dash (---)", "Custom delimiter"],
                    help="Choose how to split the abstracts"
                )
            
            with col2:
                if delimiter_type == "Custom delimiter":
                    custom_delimiter = st.text_input("Custom delimiter:", value="###")
                else:
                    custom_delimiter = None
            
            # Parse abstracts from text input
            if batch_text.strip():
                text_abstracts = self._parse_batch_abstracts(batch_text, delimiter_type, custom_delimiter)
                abstracts.extend(text_abstracts)
                source_info.extend([f"Text_Input_Abstract_{i+1}" for i in range(len(text_abstracts))])
                
                if text_abstracts:
                    st.success(f"üìä Found {len(text_abstracts)} abstracts from text input")
                else:
                    st.warning("‚ö†Ô∏è Could not parse any abstracts from the text. Please check the format and delimiters.")
        
        with file_tab:
            st.markdown("**Upload multiple files for batch processing:**")
            
            # Multiple file uploader
            uploaded_files = st.file_uploader(
                "Choose multiple files",
                type=["pdf", "docx", "txt"],
                accept_multiple_files=True,
                help="Supported formats: PDF, Word documents, and text files. Select multiple files for batch processing."
            )
            
            if uploaded_files:
                st.success(f"üìÅ Selected {len(uploaded_files)} files for processing")
                
                # Display file summary
                with st.expander("üìã File Summary", expanded=True):
                    file_data = []
                    total_size = 0
                    
                    for file in uploaded_files:
                        file_size_kb = file.size / 1024
                        total_size += file_size_kb
                        file_data.append({
                            "File Name": file.name,
                            "Type": file.type.split('/')[-1].upper(),
                            "Size (KB)": f"{file_size_kb:.1f}"
                        })
                    
                    import pandas as pd
                    df = pd.DataFrame(file_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Total Files", len(uploaded_files))
                    with col2:
                        st.metric("Total Size", f"{total_size:.1f} KB")
                    with col3:
                        file_types = list(set([f.type.split('/')[-1].upper() for f in uploaded_files]))
                        st.metric("File Types", ", ".join(file_types))
                
                # Extract text from uploaded files
                file_abstracts = []
                file_sources = []
                
                for uploaded_file in uploaded_files:
                    try:
                        # Extract text from file
                        file_content = uploaded_file.read()
                        if uploaded_file.type == "application/pdf":
                            from utils.file_processors import FileProcessor
                            processor = FileProcessor()
                            text_content = processor.process_file(file_content, uploaded_file.name)
                        else:
                            # Handle text files and other formats
                            text_content = file_content.decode('utf-8', errors='ignore')
                        
                        if text_content.strip():
                            file_abstracts.append(text_content.strip())
                            file_sources.append(uploaded_file.name)
                    
                    except Exception as e:
                        st.error(f"‚ùå Failed to process {uploaded_file.name}: {str(e)}")
                
                abstracts.extend(file_abstracts)
                source_info.extend(file_sources)
                
                if file_abstracts:
                    st.info(f"üìÑ Successfully extracted text from {len(file_abstracts)} files")
        
        # Common processing options (Developer mode only)
        if abstracts:
            st.markdown("---")
            
            # Show batch processing configuration only in developer mode
            if st.session_state.developer_mode:
                st.markdown("### ‚öôÔ∏è Batch Processing Configuration")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Processing Options:**")
                    batch_size = st.number_input("Batch size:", min_value=1, max_value=10, value=3, help="Number of abstracts to process simultaneously")
                    skip_errors = st.checkbox("Skip errors", value=True, help="Continue processing if some abstracts fail")
                    auto_categorize = st.checkbox("Auto-categorize", value=True, help="Automatically categorize all studies")
                
                with col2:
                    st.markdown("**Advanced Options:**")
                    create_embeddings = st.checkbox("Create embeddings", value=True, help="Generate vector embeddings for AI search")
                    quality_check = st.checkbox("Quality validation", value=True, help="Validate extraction quality before storing")
                    detailed_logging = st.checkbox("Detailed logging", value=False, help="Show detailed processing logs")
            else:
                # Default values when developer mode is off
                batch_size = 3
                skip_errors = True
                auto_categorize = True
                create_embeddings = True
                quality_check = True
                detailed_logging = False
            
            # Summary before processing
            st.markdown("### üìä Processing Summary")
            summary_col1, summary_col2, summary_col3 = st.columns(3)
            
            with summary_col1:
                st.metric("üìÑ Total Abstracts", len(abstracts))
            with summary_col2:
                text_count = len([s for s in source_info if s.startswith("Text_Input")])
                file_count = len([s for s in source_info if not s.startswith("Text_Input")])
                st.metric("üìù From Text", text_count)
            with summary_col3:
                st.metric("üìÅ From Files", file_count)
            
            # Process button
            if st.button("üöÄ Start Batch Processing", type="primary", use_container_width=True):
                self._process_batch_abstracts(abstracts, source_info, {
                    'batch_size': batch_size,
                    'skip_errors': skip_errors,
                    'auto_categorize': auto_categorize,
                    'create_embeddings': create_embeddings,
                    'quality_check': quality_check,
                    'detailed_logging': detailed_logging
                })
        
        else:
            st.info("üëÜ **Getting Started**: Use the tabs above to input abstracts via text or upload files for batch processing.")
    
    def _process_batch_abstracts(self, abstracts: List[str], source_info: List[str], options: Dict):
        """Process multiple abstracts with comprehensive tracking and error handling"""
        
        # Initialize batch processing
        start_time = time.time()
        processed_count = 0
        failed_count = 0
        processing_details = []
        
        # Create progress tracking
        progress_bar = st.progress(0)
        status_container = st.container()
        results_container = st.container()
        
        # Process abstracts in batches
        batch_size = options['batch_size']
        total_abstracts = len(abstracts)
        
        with status_container:
            st.markdown("### üîÑ Processing Status")
        
        for i in range(0, total_abstracts, batch_size):
            batch = abstracts[i:i + batch_size]
            batch_sources = source_info[i:i + batch_size]
            
            with status_container:
                st.markdown(f"**üìã Processing Batch {i//batch_size + 1}/{(total_abstracts + batch_size - 1)//batch_size}**")
            
            for j, (abstract, source) in enumerate(zip(batch, batch_sources)):
                current_index = i + j + 1
                progress = current_index / total_abstracts
                progress_bar.progress(progress)
                
                processing_detail = {
                    'index': current_index,
                    'source': source,
                    'status': 'processing',
                    'start_time': time.time(),
                    'errors': []
                }
                
                try:
                    if options['detailed_logging']:
                        with status_container:
                            with st.expander(f"üìÑ Processing {current_index}/{total_abstracts}: {source}", expanded=True):
                                st.write(f"**Source:** {source}")
                                st.write(f"**Content preview:** {abstract[:200]}...")
                                
                                # Extract metadata
                                st.write("üîç Extracting metadata...")
                                processing_start = time.time()
                                
                                extracted_data = asyncio.run(
                                    self.metadata_extractor.extract_comprehensive_metadata(abstract)
                                )
                                
                                # Quality check
                                if options['quality_check']:
                                    st.write("‚úÖ Validating quality...")
                                    quality_score = self._calculate_clinical_significance_safe(extracted_data)
                                    if quality_score < 0.3:
                                        st.warning(f"‚ö†Ô∏è Low quality score: {quality_score:.2f}")
                                
                                # Categorize if enabled
                                categorization_data = None
                                if options['auto_categorize']:
                                    st.write("üè∑Ô∏è Categorizing study...")
                                    categorization_data = asyncio.run(
                                        self.categorizer.categorize_study(abstract, extracted_data.model_dump())
                                    )
                                
                                # Create embeddings if enabled
                                if options['create_embeddings'] and self._get_vector_store():
                                    st.write("üß† Creating embeddings...")
                                    asyncio.run(
                                        self._get_vector_store().embed_abstract(extracted_data)
                                    )
                                
                                processing_time = time.time() - processing_start
                                st.success(f"‚úÖ Completed in {processing_time:.1f}s")
                    
                    else:
                        # Silent processing
                        extracted_data = asyncio.run(
                            self.metadata_extractor.extract_comprehensive_metadata(abstract)
                        )
                        
                        categorization_data = None
                        if options['auto_categorize']:
                            categorization_data = asyncio.run(
                                self.categorizer.categorize_study(abstract, extracted_data.model_dump())
                            )
                        
                        if options['create_embeddings'] and self._get_vector_store():
                            asyncio.run(
                                self._get_vector_store().embed_abstract(extracted_data)
                            )
                    
                    # Store results
                    extracted_data.source_file = source
                    
                    if 'extracted_data' not in st.session_state:
                        st.session_state.extracted_data = []
                    if 'categorization_data' not in st.session_state:
                        st.session_state.categorization_data = []
                    
                    st.session_state.extracted_data.append(extracted_data)
                    st.session_state.categorization_data.append(categorization_data or {})
                    
                    processed_count += 1
                    processing_detail['status'] = 'success'
                    processing_detail['processing_time'] = time.time() - processing_detail['start_time']
                    
                except Exception as e:
                    failed_count += 1
                    error_msg = str(e)
                    processing_detail['status'] = 'failed'
                    processing_detail['errors'].append(error_msg)
                    
                    with status_container:
                        st.error(f"‚ùå Failed to process {source}: {error_msg}")
                    
                    if not options['skip_errors']:
                        st.error("‚ùå Processing stopped due to error. Enable 'Skip errors' to continue with remaining abstracts.")
                        break
                
                processing_details.append(processing_detail)
        
        # Final results
        total_time = time.time() - start_time
        progress_bar.progress(1.0)
        
        # Update session stats
        if processed_count > 0:
            self._update_session_stats(total_time, processed_count)
        
        # Display comprehensive results
        with results_container:
            st.markdown("---")
            st.markdown("### üìä Batch Processing Results")
            
            # Summary metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("‚úÖ Processed", processed_count)
            with col2:
                st.metric("‚ùå Failed", failed_count)
            with col3:
                st.metric("‚è±Ô∏è Total Time", f"{total_time:.1f}s")
            with col4:
                avg_time = total_time / len(abstracts) if abstracts else 0
                st.metric("‚ö° Avg Time/Abstract", f"{avg_time:.1f}s")
            
            # Detailed results table
            if processing_details:
                with st.expander("üìã Detailed Processing Report", expanded=True):
                    results_data = []
                    for detail in processing_details:
                        results_data.append({
                            "Index": detail['index'],
                            "Source": detail['source'],
                            "Status": "‚úÖ Success" if detail['status'] == 'success' else "‚ùå Failed",
                            "Time (s)": f"{detail.get('processing_time', 0):.1f}",
                            "Errors": "; ".join(detail['errors']) if detail['errors'] else "None"
                        })
                    
                    import pandas as pd
                    df = pd.DataFrame(results_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
            
            # Final status message
            if processed_count > 0:
                st.success(f"üéâ **Batch processing completed!** {processed_count} abstracts processed successfully in {total_time:.1f}s.")
                if failed_count > 0:
                    st.warning(f"‚ö†Ô∏è {failed_count} abstracts failed to process. Check the detailed report above for specifics.")
                
                # Auto-rerun to refresh the interface
                st.rerun()
            else:
                st.error("‚ùå No abstracts were processed successfully. Please check your input data and try again.")
    
    def _parse_batch_abstracts(self, batch_text: str, delimiter_type: str, custom_delimiter: str = None) -> List[str]:
        """Parse batch text into individual abstracts"""
        abstracts = []
        
        if delimiter_type == "Auto-detect":
            # Try different delimiters in order of preference
            if "---" in batch_text:
                abstracts = [abs.strip() for abs in batch_text.split("---") if abs.strip()]
            elif "\n\n\n" in batch_text:
                abstracts = [abs.strip() for abs in batch_text.split("\n\n\n") if abs.strip()]
            elif "\n\n" in batch_text:
                abstracts = [abs.strip() for abs in batch_text.split("\n\n") if abs.strip()]
            else:
                # Fallback: split by periods followed by capital letters (crude but sometimes works)
                import re
                potential_splits = re.split(r'\.\s+(?=[A-Z][a-z])', batch_text)
                abstracts = [abs.strip() for abs in potential_splits if len(abs.strip()) > 100]
        
        elif delimiter_type == "Blank lines":
            abstracts = [abs.strip() for abs in batch_text.split("\n\n") if abs.strip()]
        
        elif delimiter_type == "Triple dash (---)":
            abstracts = [abs.strip() for abs in batch_text.split("---") if abs.strip()]
        
        elif delimiter_type == "Custom delimiter" and custom_delimiter:
            abstracts = [abs.strip() for abs in batch_text.split(custom_delimiter) if abs.strip()]
        
        # Filter out very short "abstracts" (likely not real abstracts)
        abstracts = [abs for abs in abstracts if len(abs) > 50]
        
        return abstracts
    
    def _show_processing_results(self, results: Dict, processing_time: float):
        """Show comprehensive detailed processing results for clinical professionals"""
        
        st.markdown("#### üìä Processing Results")
        
        # Quick Status Overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if results['metadata_extraction']['status'] == 'success':
                st.metric("Metadata", "‚úÖ Success", delta="Extracted")
            else:
                st.metric("Metadata", "‚ùå Failed", delta="Error")
        
        with col2:
            if results['categorization']['status'] == 'success':
                st.metric("Categorization", "‚úÖ Success", delta="Completed")
            elif results['categorization']['status'] == 'failed':
                st.metric("Categorization", "‚ùå Failed", delta="Error")
            else:
                st.metric("Categorization", "‚è≠Ô∏è Skipped", delta="Not requested")
        
        with col3:
            if results['vector_embedding']['status'] == 'success':
                vectors_created = results['vector_embedding']['data'].get('vectors_created', 0)
                st.metric("Vector Embedding", "‚úÖ Success", delta=f"{vectors_created} chunks")
            elif results['vector_embedding']['status'] == 'skipped':
                st.metric("Vector Embedding", "‚è≠Ô∏è Skipped", delta="Duplicate")
            elif results['vector_embedding']['status'] == 'failed':
                st.metric("Vector Embedding", "‚ùå Failed", delta="Error")
            else:
                st.metric("Vector Embedding", "‚è≠Ô∏è Skipped", delta="Not requested")
        
        with col4:
            st.metric("Processing Time", f"{processing_time:.1f}s", delta="Duration")
        
        # Comprehensive Detailed Results
        if results['metadata_extraction']['status'] == 'success':
            data = results['metadata_extraction']['data']
            
            # === EXECUTIVE SUMMARY ===
            with st.expander("üìã **Executive Summary & Key Highlights**", expanded=True):
                st.markdown("### üéØ **Clinical Summary**")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("**Study Type & Phase**")
                    study_type = self._safe_get(data, 'study_design.study_type.value') or self._safe_get(data, 'study_design.study_type') or "Not specified"
                    st.info(f"üî¨ **{study_type}**")
                    
                    acronym = self._safe_get(data, 'study_identification.study_acronym')
                    if acronym:
                        st.write(f"**Acronym:** {acronym}")
                    
                    nct = self._safe_get(data, 'study_identification.nct_number')
                    if nct:
                        st.write(f"**NCT:** {nct}")
                
                with col2:
                    st.markdown("**Key Efficacy**")
                    
                    # Overall Response Rate
                    orr_value = self._safe_get(data, 'efficacy_outcomes.overall_response_rate.value')
                    if orr_value:
                        st.success(f"üìà **ORR: {orr_value}%**")
                    
                    # Progression Free Survival
                    pfs_median = self._safe_get(data, 'efficacy_outcomes.progression_free_survival.median')
                    if pfs_median:
                        st.success(f"‚è±Ô∏è **PFS: {pfs_median} months**")
                    
                    # Overall Survival
                    os_median = self._safe_get(data, 'efficacy_outcomes.overall_survival.median')
                    if os_median:
                        st.success(f"üéØ **OS: {os_median} months**")
                
                with col3:
                    st.markdown("**Patient Population**")
                    
                    total_enrolled = self._safe_get(data, 'patient_demographics.total_enrolled')
                    if total_enrolled:
                        st.info(f"üë• **N = {total_enrolled}**")
                    
                    median_age = self._safe_get(data, 'patient_demographics.median_age')
                    if median_age:
                        st.write(f"**Median Age:** {median_age}")
                    
                    mm_subtype = self._safe_get(data, 'disease_characteristics.mm_subtype')
                    if mm_subtype:
                        if isinstance(mm_subtype, list):
                            st.write(f"**Population:** {', '.join([str(s) for s in mm_subtype])}")
                        else:
                            st.write(f"**Population:** {mm_subtype}")
                
                # Clinical Significance Alert
                quality_score = self._calculate_clinical_significance_safe(data)
                if quality_score >= 0.8:
                    st.success("üèÜ **HIGH CLINICAL SIGNIFICANCE** - This study presents important clinical findings with robust data")
                elif quality_score >= 0.6:
                    st.info("‚≠ê **MODERATE CLINICAL SIGNIFICANCE** - Notable findings with good data quality")
                else:
                    st.warning("‚ö†Ô∏è **LIMITED CLINICAL SIGNIFICANCE** - Preliminary or incomplete data")
            
            # === COMPREHENSIVE METADATA DISPLAY ===
            st.markdown("---")
            self._show_comprehensive_metadata_display(data)
            
            # === CLINICAL INSIGHTS ===
            with st.expander("üî¨ **Clinical Insights & Professional Analysis**", expanded=True):
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### üéØ **Key Clinical Takeaways**")
                    
                    # Generate clinical insights
                    insights = self._generate_clinical_insights_safe(data)
                    for insight in insights:
                        st.markdown(f"‚Ä¢ {insight}")
                    
                    st.markdown("### üìä **Data Quality Assessment**") 
                    quality_metrics = self._assess_data_quality_safe(data)
                    for metric, score in quality_metrics.items():
                        if score >= 0.8:
                            st.success(f"‚úÖ **{metric}**: Excellent ({score:.1%})")
                        elif score >= 0.6:
                            st.info(f"‚ÑπÔ∏è **{metric}**: Good ({score:.1%})")
                        else:
                            st.warning(f"‚ö†Ô∏è **{metric}**: Limited ({score:.1%})")
                
                with col2:
                    st.markdown("### üè• **Clinical Practice Implications**")
                    
                    implications = self._generate_practice_implications_safe(data)
                    for implication in implications:
                        st.markdown(f"‚Ä¢ {implication}")
                    
                    st.markdown("### üîÑ **Regulatory & Commercial Context**")
                    context = self._generate_regulatory_context_safe(data)
                    for point in context:
                        st.markdown(f"‚Ä¢ {point}")
        
        # Vector Embedding Details
        if results['vector_embedding']['status'] == 'success':
            with st.expander("üß† **Vector Embedding & AI Search Details**"):
                embedding_data = results['vector_embedding']['data']
                st.write(f"**Study:** {embedding_data['study_title']}")
                st.write(f"**Vectors Created:** {embedding_data['vectors_created']}")
                st.write(f"**Chunk Types:** {', '.join(embedding_data['chunk_types'])}")
                st.write(f"**Content Hash:** {embedding_data['content_hash']}")
                st.info("üí° This study is now searchable via the AI Assistant for intelligent clinical queries.")
    
    def _safe_get(self, obj, path: str, default=None):
        """Safely get nested attributes from object or dictionary"""
        try:
            keys = path.split('.')
            current = obj
            for key in keys:
                if isinstance(current, dict):
                    current = current.get(key, default)
                else:
                    current = getattr(current, key, default)
                if current is None:
                    return default
            return current
        except:
            return default
    
    def _calculate_clinical_significance_safe(self, data) -> float:
        """Calculate overall clinical significance score safely"""
        score = 0.0
        
        # Study type weight
        study_type = self._safe_get(data, 'study_design.study_type.value') or self._safe_get(data, 'study_design.study_type', '')
        if "Phase 3" in str(study_type):
            score += 0.3
        elif "Phase 2" in str(study_type):
            score += 0.2
        
        # Sample size weight
        total_enrolled = self._safe_get(data, 'patient_demographics.total_enrolled')
        if total_enrolled:
            try:
                total_enrolled = int(total_enrolled)
                if total_enrolled >= 500:
                    score += 0.2
                elif total_enrolled >= 100:
                    score += 0.15
                else:
                    score += 0.1
            except:
                score += 0.1
        
        # Efficacy data weight
        orr_value = self._safe_get(data, 'efficacy_outcomes.overall_response_rate.value')
        if orr_value:
            try:
                orr_value = float(orr_value)
                if orr_value >= 80:
                    score += 0.25
                elif orr_value >= 60:
                    score += 0.2
                else:
                    score += 0.1
            except:
                score += 0.1
        
        # Survival data weight
        pfs_median = self._safe_get(data, 'efficacy_outcomes.progression_free_survival.median')
        if pfs_median:
            try:
                pfs_median = float(pfs_median)
                if pfs_median >= 24:
                    score += 0.25
                elif pfs_median >= 12:
                    score += 0.15
                else:
                    score += 0.1
            except:
                score += 0.1
        
        return min(score, 1.0)
    
    def _assess_ae_significance_safe(self, grade_3_4_rate) -> str:
        """Assess clinical significance of adverse event rate safely"""
        if not grade_3_4_rate or grade_3_4_rate == "Not reported":
            return "Unknown"
        
        try:
            rate = float(grade_3_4_rate)
            if rate >= 50:
                return "High Concern"
            elif rate >= 25:
                return "Moderate Concern"
            elif rate >= 10:
                return "Low Concern"
            else:
                return "Minimal Concern"
        except:
            return "Unknown"
    
    def _generate_clinical_insights_safe(self, data) -> List[str]:
        """Generate key clinical insights from the data safely"""
        insights = []
        
        # Study design insights
        study_type = self._safe_get(data, 'study_design.study_type.value') or self._safe_get(data, 'study_design.study_type', 'Unknown')
        evidence_level = self._get_evidence_level_safe(study_type)
        insights.append(f"This {study_type} study provides {evidence_level} evidence")
        
        # Population insights
        total_enrolled = self._safe_get(data, 'patient_demographics.total_enrolled')
        if total_enrolled:
            try:
                total_enrolled = int(total_enrolled)
                if total_enrolled >= 300:
                    insights.append(f"Large study population (N={total_enrolled}) enhances statistical power")
                elif total_enrolled >= 100:
                    insights.append(f"Adequate study population (N={total_enrolled}) for meaningful analysis")
            except:
                insights.append(f"Study population data available (N={total_enrolled})")
        
        # Efficacy insights
        orr_value = self._safe_get(data, 'efficacy_outcomes.overall_response_rate.value')
        if orr_value:
            try:
                orr = float(orr_value)
                if orr >= 80:
                    insights.append(f"Exceptional response rate ({orr}%) suggests highly active regimen")
                elif orr >= 60:
                    insights.append(f"Strong response rate ({orr}%) indicates clinically meaningful activity")
            except:
                insights.append(f"Response rate data available ({orr_value}%)")
        
        return insights
    
    def _generate_practice_implications_safe(self, data) -> List[str]:
        """Generate clinical practice implications safely"""
        implications = []
        
        # Treatment setting implications
        mm_subtype = self._safe_get(data, 'mm_subtype')
        if mm_subtype:
            mm_types = mm_subtype if isinstance(mm_subtype, list) else [mm_subtype]
            if any("Newly Diagnosed" in str(t) for t in mm_types):
                implications.append("Findings relevant for first-line treatment decisions")
            elif any("Relapsed" in str(t) or "Refractory" in str(t) for t in mm_types):
                implications.append("Important for relapsed/refractory treatment sequencing")
        
        # Efficacy implications
        pfs_median = self._safe_get(data, 'efficacy_outcomes.progression_free_survival.median')
        if pfs_median:
            try:
                pfs = float(pfs_median)
                if pfs >= 24:
                    implications.append("Extended PFS supports potential for durable disease control")
                elif pfs >= 12:
                    implications.append("Reasonable PFS suggests meaningful clinical benefit")
            except:
                implications.append("PFS data provides treatment duration insights")
        
        # Patient selection implications
        median_age = self._safe_get(data, 'patient_demographics.median_age')
        if median_age:
            try:
                age = float(median_age)
                if age >= 70:
                    implications.append("Safety data particularly relevant for elderly MM patients")
                elif age <= 65:
                    implications.append("Results applicable to younger, potentially transplant-eligible patients")
            except:
                implications.append("Age distribution data available for patient selection")
        
        return implications if implications else ["Clinical practice implications depend on complete data availability"]
    
    def _generate_regulatory_context_safe(self, data) -> List[str]:
        """Generate regulatory and commercial context safely"""
        context = []
        
        # Study phase context
        study_type = self._safe_get(data, 'study_design.study_type.value') or self._safe_get(data, 'study_design.study_type', '')
        if "Phase 3" in str(study_type):
            context.append("Phase 3 data supports potential regulatory submissions")
        elif "Phase 2" in str(study_type):
            context.append("Phase 2 data provides proof-of-concept for further development")
        
        # Competitive landscape
        orr_value = self._safe_get(data, 'efficacy_outcomes.overall_response_rate.value')
        if orr_value:
            try:
                orr = float(orr_value)
                if orr >= 85:
                    context.append("Best-in-class potential based on response rates")
                elif orr >= 70:
                    context.append("Competitive efficacy profile in current treatment landscape")
            except:
                context.append("Efficacy data available for competitive assessment")
        
        # Market access considerations
        safety_profile = self._safe_get(data, 'safety_profile')
        if safety_profile:
            context.append("Safety profile will be key factor in market access decisions")
        
        return context if context else ["Regulatory context depends on study phase and data maturity"]
    
    def _get_evidence_level_safe(self, study_type: str) -> str:
        """Get evidence level based on study type safely"""
        study_type_str = str(study_type).lower()
        if "phase 3" in study_type_str:
            return "high-level"
        elif "phase 2" in study_type_str:
            return "moderate-level"
        elif "phase 1" in study_type_str:
            return "preliminary"
        else:
            return "supporting"
    
    def _assess_data_quality_safe(self, data) -> Dict[str, float]:
        """Assess quality of different data domains safely"""
        quality = {}
        
        # Study identification completeness
        id_fields = [
            self._safe_get(data, 'study_identification.title'),
            self._safe_get(data, 'study_identification.nct_number'),
            self._safe_get(data, 'study_identification.study_acronym')
        ]
        quality["Study Identification"] = sum(1 for field in id_fields if field) / len(id_fields)
        
        # Demographics completeness
        demo_fields = [
            self._safe_get(data, 'patient_demographics.total_enrolled'),
            self._safe_get(data, 'patient_demographics.median_age'),
            self._safe_get(data, 'patient_demographics.male_percentage')
        ]
        quality["Demographics"] = sum(1 for field in demo_fields if field) / len(demo_fields)
        
        # Efficacy completeness
        eff_fields = [
            self._safe_get(data, 'efficacy_outcomes.overall_response_rate'),
            self._safe_get(data, 'efficacy_outcomes.progression_free_survival')
        ]
        quality["Efficacy Data"] = sum(1 for field in eff_fields if field) / len(eff_fields)
        
        # Treatment details
        treatment_regimens = self._safe_get(data, 'treatment_regimens')
        quality["Treatment Details"] = 1.0 if treatment_regimens else 0.0
        
        return quality
    
    def _export_comprehensive_data(self, data):
        """Export comprehensive dataset"""
        # Implementation for data export
        pass
    
    def _generate_clinical_summary_report(self, data):
        """Generate clinical summary report"""
        # Implementation for summary report
        pass
    
    def _generate_citation(self, data) -> str:
        """Generate academic citation"""
        title = data.study_identification.title
        acronym = data.study_identification.study_acronym
        nct = data.study_identification.nct_number
        
        citation = f"{title}"
        if acronym:
            citation += f" ({acronym})"
        if nct:
            citation += f" [{nct}]"
        citation += f". {data.study_design.study_type.value} study."
        
        return citation

    def _extract_orr(self, data: ComprehensiveAbstractMetadata) -> str:
        """Extract ORR value for display"""
        orr_data = data.efficacy_outcomes.overall_response_rate
        if orr_data and isinstance(orr_data, dict):
            for key in ['value', 'rate', 'percentage']:
                if key in orr_data:
                    try:
                        return f"{float(orr_data[key]):.1f}"
                    except (ValueError, TypeError):
                        continue
        return "N/A"
    
    def _extract_pfs(self, data: ComprehensiveAbstractMetadata) -> str:
        """Extract PFS value for display"""
        pfs_data = data.efficacy_outcomes.progression_free_survival
        if pfs_data and isinstance(pfs_data, dict):
            for key in ['median', 'value', 'months']:
                if key in pfs_data:
                    try:
                        return f"{float(pfs_data[key]):.1f}"
                    except (ValueError, TypeError):
                        continue
        return "N/A"
    
    def _export_data(self):
        """Export extracted data"""
        
        export_data = []
        for data in st.session_state.extracted_data:
            export_data.append({
                'abstract_id': data.abstract_id,
                'title': data.study_identification.title,
                'study_type': data.study_design.study_type.value,
                'total_enrolled': data.patient_demographics.total_enrolled,
                'extraction_confidence': data.extraction_confidence,
                'extraction_timestamp': data.extraction_timestamp.isoformat()
            })
        
        df = pd.DataFrame(export_data)
        
        # Create download
        csv = df.to_csv(index=False)
        st.download_button(
            label="üì• Download CSV",
            data=csv,
            file_name=f"ascomind_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    def render_research_explorer(self):
        """Render research explorer page"""
        st.title("üîç Research Data Explorer")
        st.info("üöß Advanced research exploration interface coming soon!")
    
    def render_treatment_intelligence(self):
        """Render treatment intelligence page"""
        st.title("üíä Treatment Landscape Intelligence")
        st.info("üöß Treatment intelligence dashboard coming soon!")
    
    def render_market_analytics(self):
        """Render market analytics page"""
        st.title("üìà Market Analytics & Commercial Intelligence")
        st.info("üöß Market analytics platform coming soon!")
    
    def render_ai_assistant(self):
        """Render AI assistant chatbot page with improved performance and UX"""
        
        st.markdown("""
        <div class="section-header">
            <h2>ü§ñ Dr. ASCOmind+ | AI Research Assistant</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Initialize components with lazy loading and session awareness
        if not hasattr(self, '_ai_assistant_initialized'):
            self.ai_assistant = self._get_ai_assistant()
            self.vector_store = self._get_vector_store()
            self._ai_assistant_initialized = True
        
        # Session information header
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
                    color: white; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
            <h3 style="margin: 0; color: white;">ü§ñ AI Research Assistant</h3>
            <p style="margin: 0.5rem 0 0 0; opacity: 0.9; font-size: 0.9rem;">
                Session: {st.session_state.session_id[:12]}... | 
                Data Isolated: ‚úÖ Only your studies
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Developer mode controls
        if st.session_state.developer_mode:
            with st.expander("üõ†Ô∏è Developer Controls", expanded=False):
                st.markdown("**üß† LLM Provider Selection:**")
                
                # Get available providers
                available_providers = settings.get_available_providers()
                enabled_providers = [provider for provider, available in available_providers.items() if available]
                
                if enabled_providers:
                    provider_options = {}
                    for provider in enabled_providers:
                        config = settings.get_provider_config(provider)
                        provider_options[f"{config['icon']} {config['name']} ({provider})"] = provider
                    
                    selected_display = st.selectbox(
                        "Choose LLM Provider:",
                        options=list(provider_options.keys()),
                        index=list(provider_options.values()).index(st.session_state.selected_llm_provider) 
                        if st.session_state.selected_llm_provider in provider_options.values() else 0,
                        key="llm_provider_select"
                    )
                    
                    # Update session state when selection changes
                    new_provider = provider_options[selected_display]
                    if new_provider != st.session_state.selected_llm_provider:
                        st.session_state.selected_llm_provider = new_provider
                        st.success(f"‚úÖ Switched to {selected_display}")
                        st.rerun()
                    
                    # Show provider status
                    col1, col2, col3 = st.columns(3)
                    for i, (provider, available) in enumerate(available_providers.items()):
                        col = [col1, col2, col3][i % 3]
                        config = settings.get_provider_config(provider)
                        status = "‚úÖ" if available else "‚ùå"
                        current = "üéØ" if provider == st.session_state.selected_llm_provider else ""
                        col.write(f"{status} {config['icon']} {config['name']} {current}")
                else:
                    st.error("‚ùå No LLM providers available! Check your API keys in secrets.")
                
                st.markdown("---")
                st.markdown("**üîß Quick Actions:**")
                if st.button("üîÑ Refresh API Keys", key="refresh_api_keys"):
                    settings.refresh_from_secrets()
                    st.success("API keys refreshed!")
                    st.rerun()
        
        # Simplified sidebar with session info
        with st.sidebar:
            st.markdown("### ü§ñ Assistant Status")
            st.success("‚úÖ Ready")
            
            # Session info
            st.markdown("### üìä Session Info")
            st.info(f"Session: {st.session_state.session_id[:12]}...")
            st.metric("Studies in Session", len(st.session_state.extracted_data))
            
            # Session management
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìä Refresh Stats", key="ai_refresh_stats"):
                    # Get fresh statistics
                    if self.vector_store:
                        vector_stats = self.vector_store.get_statistics()
                        st.json(vector_stats)
                    else:
                        st.warning("Vector store not available")
            
            with col2:
                if st.button("üóëÔ∏è Clear Session Data", key="ai_clear_session"):
                    if self.vector_store:
                        result = asyncio.run(self.vector_store.clear_session_data())
                        if result["status"] == "success":
                            st.success(f"Cleared {result['vectors_deleted']} vectors")
                            # Also clear session state
                            st.session_state.extracted_data = []
                            st.session_state.ai_conversation_history = []
                            st.rerun()
                        else:
                            st.error("Failed to clear session data")
                    else:
                        # Just clear session state if no vector store
                        st.session_state.extracted_data = []
                        st.session_state.ai_conversation_history = []
                        st.success("Session data cleared")
                        st.rerun()
        
        # Display conversation history (optimized)
        if st.session_state.ai_conversation_history:
            st.markdown("### üí¨ Conversation History")
            
            # Show only last 2 exchanges to improve performance
            recent_exchanges = st.session_state.ai_conversation_history[-2:]
            
            for i, exchange in enumerate(recent_exchanges):
                with st.chat_message("user"):
                    st.write(exchange.get('user_message', ''))
                
                with st.chat_message("assistant"):
                    response_data = exchange.get('response_data', {})
                    st.write(response_data.get('response', 'No response available'))
                    
                    # Show studies count if available
                    if response_data.get('studies_referenced', 0) > 0:
                        st.caption(f"üìö Referenced {response_data['studies_referenced']} studies")
            
            if len(st.session_state.ai_conversation_history) > 2:
                st.caption(f"... and {len(st.session_state.ai_conversation_history) - 2} earlier exchanges")
        
        # Chat input with form for Enter key support
        st.markdown("### üí¨ Ask Dr. ASCOmind+")
        
        # Use form to enable Enter key submission
        with st.form("ai_chat_form", clear_on_submit=True):
            user_query = st.text_area(
                "Your question:",
                height=80,
                placeholder="Ask about multiple myeloma research, treatment comparisons, or study insights...",
                key="ai_chat_input_form"
            )
            
            # Submit button
            submitted = st.form_submit_button("üöÄ Get AI Analysis", type="primary", use_container_width=True)
        
        # Process query when form is submitted
        if submitted and user_query.strip():
            # Store the query for processing
            st.session_state.processing_query = user_query.strip()
            
            # Create a single container for the entire response process
            response_container = st.container()
            
            with response_container:
                # Simple progress indicator
                with st.spinner("üß† AI is analyzing your question..."):
                    try:
                        # Simple user context
                        user_context = {
                            'session_studies': len(st.session_state.extracted_data) if st.session_state.extracted_data else 0
                        }
                        
                        # Get AI response with timeout
                        response_data = asyncio.run(
                            asyncio.wait_for(
                                self.ai_assistant.chat(st.session_state.processing_query, user_context),
                                timeout=60.0
                            )
                        )
                        
                        # Store conversation immediately
                        conversation_entry = {
                            'user_message': st.session_state.processing_query,
                            'response_data': response_data,
                            'timestamp': datetime.now().strftime("%H:%M:%S")
                        }
                        
                        if 'ai_conversation_history' not in st.session_state:
                            st.session_state.ai_conversation_history = []
                        
                        st.session_state.ai_conversation_history.append(conversation_entry)
                        
                        # Clear the processing query
                        if 'processing_query' in st.session_state:
                            del st.session_state.processing_query
                        
                        # Show success and immediately rerun to display new conversation
                        st.success("‚ú® Response generated!")
                        st.rerun()
                        
                    except asyncio.TimeoutError:
                        st.error("‚è∞ Request timed out. Please try a simpler question.")
                        if 'processing_query' in st.session_state:
                            del st.session_state.processing_query
                    except Exception as e:
                        st.error(f"‚ùå AI Error: {str(e)}")
                        if 'processing_query' in st.session_state:
                            del st.session_state.processing_query
        
        elif submitted and not user_query.strip():
            st.warning("‚ö†Ô∏è Please enter a question.")
        
        # Quick tips (only show if no conversation history to reduce clutter)
        if not st.session_state.ai_conversation_history:
            st.info("""
            üí° **Quick Start Tips:**
            - Ask about study comparisons: "Compare the efficacy of my uploaded studies"
            - Get safety insights: "What are the main safety concerns?"
            - Request recommendations: "What treatment would you recommend?"
            
            **üí° Pro Tip:** Press Enter or Ctrl+Enter to submit your question quickly!
            """)
        
        # Debug mode - Add session and vector store information
        if st.checkbox("üîß Debug Mode", value=False, key="ai_debug_mode"):
            with st.expander("üîç Session & Vector Store Debug Information", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìä Session Information:**")
                    session_info = {
                        "session_id": st.session_state.session_id,
                        "extracted_data_count": len(st.session_state.extracted_data) if st.session_state.extracted_data else 0,
                        "ai_conversation_count": len(st.session_state.ai_conversation_history),
                        "vector_embedding_status": getattr(st.session_state, 'vector_embedding_status', [])
                    }
                    st.json(session_info)
                    
                    # Show extracted data titles
                    if st.session_state.extracted_data:
                        st.markdown("**üìö Extracted Studies:**")
                        for i, data in enumerate(st.session_state.extracted_data, 1):
                            st.write(f"{i}. {data.study_identification.title}")
                
                with col2:
                    st.markdown("**üß† Vector Store Information:**")
                    try:
                        if self.vector_store:
                            vector_stats = self.vector_store.get_statistics()
                            st.json(vector_stats)
                            
                            # Test vector store search
                            if st.button("üîç Test Vector Search", key="debug_test_vector_search"):
                                try:
                                    test_results = asyncio.run(
                                        self.vector_store.search_abstracts("test query", top_k=3)
                                    )
                                    st.write(f"**Search Results:** {len(test_results)} studies found")
                                    for result in test_results:
                                        st.write(f"- {result['study_info']['title']} (Score: {result['score']:.3f})")
                                except Exception as e:
                                    st.error(f"Vector search failed: {e}")
                        else:
                            st.warning("Vector store not initialized")
                    except Exception as e:
                        st.error(f"Error getting vector stats: {e}")
                
                # Manual embedding test
                st.markdown("---")
                st.markdown("**üîß Manual Embedding Test:**")
                if st.button("üöÄ Re-embed All Abstracts", key="debug_reembed_abstracts"):
                    if st.session_state.extracted_data and self.vector_store:
                        embedding_results = []
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, data in enumerate(st.session_state.extracted_data):
                            progress = (i + 1) / len(st.session_state.extracted_data)
                            progress_bar.progress(progress)
                            status_text.text(f"Re-embedding {i+1}/{len(st.session_state.extracted_data)}: {data.study_identification.title[:50]}...")
                            
                            try:
                                result = asyncio.run(
                                    self.vector_store.embed_abstract(data, force_update=True)
                                )
                                embedding_results.append({
                                    "study": data.study_identification.title,
                                    "status": result["status"],
                                    "vectors": result.get("vectors_created", 0)
                                })
                            except Exception as e:
                                embedding_results.append({
                                    "study": data.study_identification.title,
                                    "status": "error",
                                    "error": str(e)
                                })
                        
                        progress_bar.progress(1.0)
                        status_text.text("Re-embedding completed!")
                        st.json(embedding_results)
                        st.success("‚úÖ Re-embedding completed! Try asking questions now.")
                    else:
                        st.warning("No data to embed or vector store not available")
    
    def render_settings(self):
        """Render settings page"""
        st.title("‚öôÔ∏è System Settings")
        
        st.subheader("üîë API Configuration")
        
        # API keys configuration
        anthropic_key = st.text_input(
            "Anthropic API Key:",
            value=settings.ANTHROPIC_API_KEY or "",
            type="password",
            help="Enter your Anthropic API key for Claude access"
        )
        
        openai_key = st.text_input(
            "OpenAI API Key:",
            value=settings.OPENAI_API_KEY or "",
            type="password",
            help="Enter your OpenAI API key for GPT-4 fallback"
        )
        
        st.subheader("üéõÔ∏è Processing Settings")
        
        col1, col2 = st.columns(2)
        
        with col1:
            batch_size = st.slider(
                "Batch Size:",
                min_value=1,
                max_value=20,
                value=settings.BATCH_SIZE,
                help="Number of abstracts to process simultaneously"
            )
            
            confidence_threshold = st.slider(
                "Confidence Threshold:",
                min_value=0.0,
                max_value=1.0,
                value=settings.MIN_CONFIDENCE_THRESHOLD,
                step=0.1,
                help="Minimum confidence threshold for data validation"
            )
        
        with col2:
            temperature = st.slider(
                "LLM Temperature:",
                min_value=0.0,
                max_value=1.0,
                value=settings.TEMPERATURE,
                step=0.1,
                help="Temperature setting for LLM extraction"
            )
            
            max_tokens = st.number_input(
                "Max Tokens:",
                min_value=1000,
                max_value=8000,
                value=settings.MAX_TOKENS,
                help="Maximum tokens for LLM responses"
            )
        
        if st.button("üíæ Save Settings"):
            st.success("‚úÖ Settings saved successfully!")

    def _generate_basic_analysis(self) -> Dict[str, Any]:
        """Generate basic analysis fallback when full analysis fails"""
        data = st.session_state.extracted_data
        
        if not data:
            return {}
        
        # Basic statistics
        total_studies = len(data)
        enrollments = [d.patient_demographics.total_enrolled for d in data if d.patient_demographics.total_enrolled]
        avg_enrollment = sum(enrollments) / len(enrollments) if enrollments else 0
        
        # Study types
        study_types = {}
        for d in data:
            study_type = d.study_design.study_type.value
            study_types[study_type] = study_types.get(study_type, 0) + 1
        
        # Basic insights
        insights = [
            f"Analysis includes {total_studies} clinical studies",
            f"Average enrollment: {avg_enrollment:.0f} patients" if avg_enrollment else "Enrollment data limited",
            f"Most common study type: {max(study_types, key=study_types.get)}" if study_types else "Mixed study types"
        ]
        
        return {
            'dataset_overview': {
                'summary_statistics': {
                    'total_studies': total_studies,
                    'avg_enrollment': avg_enrollment,
                    'randomized_percentage': 0,
                    'avg_confidence': sum(d.extraction_confidence for d in data) / len(data)
                }
            },
            'clinical_insights': {
                'key_insights': insights
            },
            'treatment_landscape': {
                'regimen_frequencies': study_types
            }
        }

    def _update_session_stats(self, processing_time: float, abstracts_count: int):
        """Update session statistics with new processing data"""
        st.session_state.session_stats['total_processing_time'] += processing_time
        st.session_state.session_stats['abstracts_processed'] += abstracts_count
        st.session_state.session_stats['processing_history'].append({
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time,
            'abstracts_count': abstracts_count
        })

    def _get_session_summary(self) -> Dict[str, Any]:
        """Get session summary statistics with improved efficiency calculation"""
        stats = st.session_state.session_stats
        session_duration = time.time() - stats['session_start_time']
        
        # Improved efficiency calculation that's more realistic
        # Base efficiency on actual processing vs ideal processing time
        if session_duration > 0 and stats['abstracts_processed'] > 0:
            # Ideal time per abstract (considering API calls, processing complexity)
            ideal_time_per_abstract = 6.0  # Even more realistic expectation (6 seconds)
            ideal_total_time = stats['abstracts_processed'] * ideal_time_per_abstract
            
            # Calculate efficiency as (ideal_time / actual_time) * 100, capped at 100%
            raw_efficiency = (ideal_total_time / stats['total_processing_time']) * 100
            processing_efficiency = min(raw_efficiency, 100.0)  # Cap at 100%
            
            # Apply bonus for high-quality extractions
            if st.session_state.extracted_data:
                avg_quality = sum(d.extraction_confidence for d in st.session_state.extracted_data) / len(st.session_state.extracted_data)
                quality_bonus = max(0, (avg_quality - 0.6) * 50)  # Bonus for quality > 60%
                processing_efficiency = min(processing_efficiency + quality_bonus, 100.0)
        else:
            processing_efficiency = 0.0
        
        return {
            'session_duration': session_duration,
            'total_processing_time': stats['total_processing_time'],
            'abstracts_processed': stats['abstracts_processed'],
            'avg_time_per_abstract': stats['total_processing_time'] / max(stats['abstracts_processed'], 1),
            'processing_efficiency': processing_efficiency
        }

    def render_protocol_generator(self):
        """Render protocol generation page"""
        st.title("üî¨ AI Protocol Generator")
        
        if not st.session_state.extracted_data:
            st.info("üìã Upload and analyze abstracts first to generate analysis protocols.")
            return
        
        st.subheader("üìä Generate Analysis Protocol")
        
        # Protocol configuration
        col1, col2 = st.columns(2)
        
        with col1:
            analysis_objective = st.text_area(
                "Analysis Objective:",
                placeholder="e.g., Compare efficacy and safety of novel combinations in RRMM patients...",
                height=100
            )
            
            protocol_focus = st.selectbox(
                "Protocol Focus:",
                ["Efficacy Analysis", "Safety Analysis", "Comparative Analysis", 
                 "Meta-Analysis", "Real-World Evidence", "Biomarker Analysis", "Health Economics"]
            )
        
        with col2:
            complexity_level = st.selectbox(
                "Analysis Complexity:",
                ["Basic", "Intermediate", "Advanced", "Expert"]
            )
            
            include_subgroups = st.multiselect(
                "Include Subgroup Analyses:",
                ["High-risk vs Standard-risk", "NDMM vs RRMM", "Age-based", 
                 "Treatment mechanism", "Geographic", "Temporal trends"]
            )
        
        # User requirements
        st.subheader("üìã Additional Requirements")
        user_requirements = {}
        
        col1, col2, col3 = st.columns(3)
        with col1:
            user_requirements['timeline_weeks'] = st.number_input("Timeline (weeks):", min_value=1, max_value=52, value=8)
            user_requirements['budget_range'] = st.selectbox("Budget Range:", ["<$25K", "$25K-$75K", "$75K-$150K", ">$150K"])
        
        with col2:
            user_requirements['statistical_software'] = st.multiselect("Statistical Software:", ["R", "SAS", "STATA", "Python"])
            user_requirements['deliverable_format'] = st.multiselect("Deliverables:", ["PDF Report", "Interactive Dashboard", "Raw Data", "Code"])
        
        with col3:
            user_requirements['regulatory_focus'] = st.checkbox("Regulatory Submission Focus")
            user_requirements['publication_ready'] = st.checkbox("Publication-Ready Analysis")
        
        # Generate protocol button
        if st.button("üöÄ Generate Analysis Protocol", type="primary") and analysis_objective:
            with st.spinner("üß† Generating comprehensive analysis protocol..."):
                try:
                    # Prepare study data with categorizations
                    studies_with_categories = []
                    for i, study in enumerate(st.session_state.extracted_data):
                        study_data = {
                            'abstract_text': study.source_text or "",
                            'metadata': study.model_dump(),
                            'categorization': st.session_state.categorization_data[i] if i < len(st.session_state.categorization_data) else {}
                        }
                        studies_with_categories.append(study_data)
                    
                    # Generate protocol
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    protocol = loop.run_until_complete(
                        self.protocol_maker.generate_analysis_protocol(
                            studies_with_categories,
                            analysis_objective,
                            user_requirements
                        )
                    )
                    
                    st.session_state.protocol_results = protocol
                    st.success("‚úÖ Analysis protocol generated successfully!")
                    
                except Exception as e:
                    st.error(f"‚ùå Protocol generation failed: {str(e)}")
        
        # Display protocol results
        if st.session_state.protocol_results:
            st.subheader("üìã Generated Analysis Protocol")
            
            protocol = st.session_state.protocol_results
            
            # Protocol overview
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Protocol ID", protocol.get('protocol_id', 'N/A'))
            with col2:
                st.metric("Estimated Timeline", protocol.get('estimated_timeline', {}).get('total_duration', 'N/A'))
            with col3:
                st.metric("Studies Included", protocol.get('study_overview', {}).get('total_studies', 0))
            
            # Protocol tabs
            tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìã Overview", "üìä Statistical Plan", "üîç Quality Framework", "üìÖ Timeline", "üí∞ Resources"])
            
            with tab1:
                st.markdown("### üéØ Analysis Objective")
                st.write(protocol.get('analysis_objective', 'Not specified'))
                
                st.markdown("### üìä Study Overview")
                study_overview = protocol.get('study_overview', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**Study Characteristics:**")
                    st.write(f"- Total Studies: {study_overview.get('total_studies', 0)}")
                    st.write(f"- Study Types: {len(study_overview.get('study_types', {}))}")
                    st.write(f"- Population Types: {len(study_overview.get('population_types', {}))}")
                
                with col2:
                    st.write("**Data Quality:**")
                    quality_metrics = study_overview.get('data_quality_metrics', {})
                    st.write(f"- High Quality: {quality_metrics.get('high_quality_count', 0)} studies")
                    st.write(f"- Mean Confidence: {quality_metrics.get('mean_confidence', 0):.1%}")
                
                # Protocol recommendation
                recommendation = protocol.get('protocol_recommendation', {})
                if recommendation:
                    st.markdown("### üéØ Recommended Approach")
                    st.write(f"**Protocol Type:** {recommendation.get('recommended_protocol_type', 'Not specified')}")
                    st.write(f"**Complexity Level:** {recommendation.get('complexity_level', 'Not specified')}")
                    st.write(f"**Feasibility:** High - Based on available data quality")
            
            with tab2:
                st.markdown("### üìä Statistical Analysis Plan")
                stat_plan = protocol.get('statistical_analysis_plan', {})
                
                if 'primary_analysis' in stat_plan:
                    st.markdown("#### Primary Analysis")
                    primary = stat_plan['primary_analysis']
                    st.write(f"**Objective:** {primary.get('objective', 'Not specified')}")
                    st.write(f"**Statistical Methods:** {', '.join(primary.get('statistical_methods', []))}")
                    st.write(f"**Significance Level:** {primary.get('significance_level', 'Not specified')}")
                
                if 'secondary_analyses' in stat_plan:
                    st.markdown("#### Secondary Analyses")
                    secondary = stat_plan['secondary_analyses']
                    
                    if 'subgroup_analyses' in secondary:
                        st.write("**Subgroup Analyses:**")
                        for subgroup in secondary['subgroup_analyses']:
                            st.write(f"- {subgroup}")
            
            with tab3:
                st.markdown("### üîç Quality Assessment Framework")
                quality_framework = protocol.get('quality_assessment', {})
                
                if 'study_selection_criteria' in quality_framework:
                    selection = quality_framework['study_selection_criteria']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("#### Inclusion Criteria")
                        for criteria in selection.get('inclusion_criteria', []):
                            st.write(f"‚úÖ {criteria}")
                    
                    with col2:
                        st.markdown("#### Exclusion Criteria")
                        for criteria in selection.get('exclusion_criteria', []):
                            st.write(f"‚ùå {criteria}")
            
            with tab4:
                st.markdown("### üìÖ Project Timeline")
                timeline = protocol.get('estimated_timeline', {})
                
                if 'phases' in timeline:
                    phases = timeline['phases']
                    
                    # Create timeline visualization
                    phase_names = list(phases.keys())
                    phase_durations = list(phases.values())
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            x=phase_durations,
                            y=phase_names,
                            orientation='h',
                            marker_color='#667eea'
                        )
                    ])
                    
                    fig.update_layout(
                        title="Project Timeline by Phase",
                        xaxis_title="Duration",
                        yaxis_title="Project Phase",
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                
                # Milestones
                if 'milestones' in timeline:
                    st.markdown("#### Key Milestones")
                    for i, milestone in enumerate(timeline['milestones'], 1):
                        st.write(f"{i}. {milestone}")
            
            with tab5:
                st.markdown("### üí∞ Resource Requirements")
                resources = protocol.get('resource_requirements', {})
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'personnel' in resources:
                        st.markdown("#### Personnel Requirements")
                        personnel = resources['personnel']
                        for role, requirement in personnel.items():
                            st.write(f"**{role.replace('_', ' ').title()}:** {requirement}")
                    
                    if 'estimated_cost' in resources:
                        st.markdown("#### Estimated Cost")
                        st.write(f"**Total Budget:** {resources['estimated_cost']}")
                
                with col2:
                    if 'software_requirements' in resources:
                        st.markdown("#### Software Requirements")
                        for software in resources['software_requirements']:
                            st.write(f"- {software}")
                    
                    if 'infrastructure' in resources:
                        st.markdown("#### Infrastructure")
                        for infra in resources['infrastructure']:
                            st.write(f"- {infra}")
            
            # Export protocol
            st.subheader("üì• Export Protocol")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üìÑ Download PDF"):
                    st.info("PDF export functionality coming soon!")
            
            with col2:
                protocol_json = json.dumps(protocol, indent=2, default=str)
                st.download_button(
                    label="üìã Download JSON",
                    data=protocol_json,
                    file_name=f"protocol_{protocol.get('protocol_id', 'unknown')}.json",
                    mime="application/json"
                )
            
            with col3:
                if st.button("üìß Email Protocol"):
                    st.info("Email functionality coming soon!")

    def _get_realistic_quality_assessment(self, data: ComprehensiveAbstractMetadata) -> Dict[str, Any]:
        """Get realistic quality assessment based on extraction success rather than completeness"""
        
        # Count successful extractions (non-null, non-empty values)
        extraction_successes = 0
        total_attempts = 0
        
        # Core identification data (always expected)
        if data.study_identification.title:
            extraction_successes += 1
        total_attempts += 1
        
        if data.study_identification.study_acronym:
            extraction_successes += 1
        total_attempts += 1
        
        # Study design (usually available)
        if data.study_design.study_type:
            extraction_successes += 1
        total_attempts += 1
        
        # Demographics (often partially available)
        if data.patient_demographics.total_enrolled:
            extraction_successes += 1
        total_attempts += 1
        
        if data.patient_demographics.median_age:
            extraction_successes += 1
        total_attempts += 1
        
        # Efficacy outcomes (variable availability)
        if data.efficacy_outcomes.overall_response_rate and isinstance(data.efficacy_outcomes.overall_response_rate, dict):
            if any(data.efficacy_outcomes.overall_response_rate.values()):
                extraction_successes += 1
        total_attempts += 1
        
        if data.efficacy_outcomes.progression_free_survival and isinstance(data.efficacy_outcomes.progression_free_survival, dict):
            if any(data.efficacy_outcomes.progression_free_survival.values()):
                extraction_successes += 1
        total_attempts += 1
        
        # Treatment regimens (often available)
        if data.treatment_regimens and len(data.treatment_regimens) > 0:
            extraction_successes += 1
        total_attempts += 1
        
        # Calculate realistic quality score
        extraction_quality = extraction_successes / total_attempts if total_attempts > 0 else 0
        
        # Boost score based on LLM's own confidence
        llm_confidence_boost = min(0.2, data.extraction_confidence * 0.2)  # Up to 20% boost
        
        final_quality = min(1.0, extraction_quality + llm_confidence_boost)
        
        return {
            'quality_score': final_quality,
            'extractions_found': extraction_successes,
            'extractions_attempted': total_attempts,
            'llm_confidence': data.extraction_confidence,
            'assessment': self._get_quality_level(final_quality)
        }
    
    def _get_quality_level(self, score: float) -> str:
        """Get quality level based on realistic thresholds"""
        if score >= 0.7:
            return "Excellent"
        elif score >= 0.55:
            return "Good" 
        elif score >= 0.4:
            return "Fair"
        else:
            return "Poor"

    def _get_quality_badge(self, confidence: float) -> str:
        """Get a quality badge using realistic assessment"""
        # Use the LLM's confidence directly as it's already well-calibrated
        if confidence >= 0.8:  # LLM is quite confident
            return "‚úÖ Excellent"
        elif confidence >= 0.6:  # LLM is moderately confident
            return "‚úÖ Good"
        elif confidence >= 0.4:  # LLM has some confidence
            return "‚ö†Ô∏è Fair"
        else:
            return "‚ùå Poor"

    def _get_completeness_badge(self, completeness: float) -> str:
        """Get a completeness badge - now more descriptive and encouraging"""
        # Focus on what was found rather than what's missing
        if completeness >= 0.6:
            return "‚úÖ Comprehensive Data"
        elif 0.4 <= completeness < 0.6:
            return "‚úÖ Good Coverage"
        elif 0.25 <= completeness < 0.4:
            return "‚ö†Ô∏è Moderate Coverage"
        else:
            return "‚ùå Limited Data"

    def _get_clinical_relevance_badge(self, relevance: float) -> str:
        """Get a clinical relevance badge with improved thresholds"""
        # Use LLM confidence as proxy for clinical relevance
        if relevance >= 0.7:
            return "‚úÖ Highly Relevant"
        elif 0.5 <= relevance < 0.7:
            return "‚úÖ Clinically Relevant"
        elif 0.3 <= relevance < 0.5:
            return "‚ö†Ô∏è Moderately Relevant"
        else:
            return "‚ùå Limited Relevance"

    def _get_enhanced_quality_badge(self, confidence: float) -> str:
        """Get an enhanced HTML quality badge using LLM confidence directly"""
        # Trust the LLM's confidence assessment as it's well-calibrated
        if confidence >= 0.8:
            return '<span style="background: linear-gradient(135deg, #10b981, #34d399); color: white; padding: 0.25rem 0.75rem; border-radius: 9999px; font-size: 0.875rem; font-weight: 500; box-shadow: 0 2px 4px rgba(16, 185, 129, 0.3);">‚úÖ Excellent</span>'
        elif 0.6 <= confidence < 0.8:
            return '<span style="background: linear-gradient(135deg, #3b82f6, #60a5fa); color: white; padding: 0.25rem 0.75rem; border-radius: 9999px; font-size: 0.875rem; font-weight: 500; box-shadow: 0 2px 4px rgba(59, 130, 246, 0.3);">‚úÖ Good</span>'
        elif 0.4 <= confidence < 0.6:
            return '<span style="background: linear-gradient(135deg, #f59e0b, #fbbf24); color: white; padding: 0.25rem 0.75rem; border-radius: 9999px; font-size: 0.875rem; font-weight: 500; box-shadow: 0 2px 4px rgba(245, 158, 11, 0.3);">‚ö†Ô∏è Fair</span>'
        else:
            return '<span style="background: linear-gradient(135deg, #ef4444, #f87171); color: white; padding: 0.25rem 0.75rem; border-radius: 9999px; font-size: 0.875rem; font-weight: 500; box-shadow: 0 2px 4px rgba(239, 68, 68, 0.3);">‚ùå Poor</span>'

    def _get_analyzer(self):
        """Lazy loading for analyzer to improve performance"""
        if self.analyzer is None:
            try:
                if settings.ANTHROPIC_API_KEY and self.database:
                    import anthropic
                    llm_client = anthropic.Anthropic(api_key=settings.ANTHROPIC_API_KEY)
                    self.analyzer = IntelligentAnalyzer(self.database, llm_client)
                else:
                    # Create minimal analyzer without DB/LLM for basic functions
                    self.analyzer = IntelligentAnalyzer(None, None)
            except Exception as e:
                st.warning(f"Analyzer initialization failed: {e}")
                self.analyzer = IntelligentAnalyzer(None, None)  # Fallback
        return self.analyzer
    
    def _get_visualizer(self):
        """Lazy loading for visualizer to improve performance"""
        if self.visualizer is None:
            try:
                self.visualizer = AdvancedVisualizer()
            except Exception as e:
                st.warning(f"Visualizer initialization failed: {e}")
                self.visualizer = AdvancedVisualizer(None)  # Fallback
        return self.visualizer

    def _get_vector_store(self):
        """Get or initialize session-isolated vector store"""
        if not self.vector_store:
            try:
                from agents.vector_store import IntelligentVectorStore
                session_id = getattr(st.session_state, 'session_id', None)
                
                # Refresh settings from secrets in case they weren't loaded initially
                settings.refresh_from_secrets()
                
                # Check if we have required API keys
                if not settings.PINECONE_API_KEY:
                    st.error("üîë **Pinecone API key not configured!**")
                    st.info("""
                    **To enable vector search:**
                    1. Add your Pinecone API key to Streamlit secrets
                    2. Format: `api_keys.pinecone = "your-pinecone-key"`
                    3. Or set environment variable: `PINECONE_API_KEY`
                    
                    **Without vector search:** You can still use basic text analysis features.
                    """)
                    return None
                
                if not settings.OPENAI_API_KEY:
                    st.error("üîë **OpenAI API key not configured!**")
                    st.info("""
                    **To enable vector embeddings:**
                    1. Add your OpenAI API key to Streamlit secrets
                    2. Format: `api_keys.openai = "your-openai-key"`
                    3. Or set environment variable: `OPENAI_API_KEY`
                    """)
                    return None
                
                self.vector_store = IntelligentVectorStore(session_id=session_id)
                
                # Test the connection and get stats
                stats = self.vector_store.get_statistics()
                unique_studies = stats.get('unique_studies', 0)
                
                if unique_studies > 0:
                    st.success(f"üß† Vector store connected! Session: {session_id[:12]}... | Studies: {unique_studies}")
                else:
                    st.info(f"üß† Vector store ready! Session: {session_id[:12]}... | No studies embedded yet")
                
            except Exception as e:
                st.error(f"üö® Vector store initialization failed: {e}")
                st.warning("AI Assistant will work with limited capabilities (no semantic search).")
                
                # Provide specific help based on error type
                error_str = str(e).lower()
                if "api" in error_str or "key" in error_str:
                    st.info("üí° This looks like an API key issue. Check your Pinecone and OpenAI keys in Streamlit secrets.")
                elif "pinecone" in error_str:
                    st.info("üí° This looks like a Pinecone service issue. Check your Pinecone index configuration.")
                
                return None
        return self.vector_store
    
    def _get_ai_assistant(self):
        """Get or initialize session-isolated AI assistant"""
        if not self.ai_assistant:
            try:
                from agents.ai_assistant import AdvancedAIAssistant
                session_id = getattr(st.session_state, 'session_id', None)
                selected_provider = getattr(st.session_state, 'selected_llm_provider', settings.DEFAULT_LLM_PROVIDER)
                
                self.ai_assistant = AdvancedAIAssistant(
                    vector_store=self._get_vector_store(),
                    llm_provider=selected_provider
                )
                st.success(f"ü§ñ AI Assistant initialized with {selected_provider.title()} for session: {session_id[:12]}...")
            except Exception as e:
                st.error(f"AI Assistant initialization failed: {e}")
        return self.ai_assistant

    # === COMPREHENSIVE METADATA DISPLAY METHODS ===
    
    def _show_comprehensive_metadata_display(self, data):
        """Display comprehensive metadata in organized tabs"""
        st.markdown("---")
        st.markdown("## üìã **Detailed Extraction Results**")
        st.markdown("*Complete clinical data extraction with 100+ fields across all categories*")
        
        # Create tabs for organized display
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üìÑ Study Design", 
            "üìä Results & Efficacy", 
            "üë• Patient Population", 
            "üíä Treatment Regimens", 
            "‚ö†Ô∏è Safety Profile"
        ])
        
        with tab1:
            self._display_study_design_tab(data)
            
        with tab2:
            self._display_results_efficacy_tab(data)
            
        with tab3:
            self._display_patient_population_tab(data)
            
        with tab4:
            self._display_treatment_regimens_tab(data)
            
        with tab5:
            self._display_safety_profile_tab(data)
    
    def _display_study_design_tab(self, data):
        """Display Study Design tab content with beautiful card-based layout"""
        
        # Custom CSS for badges and cards
        st.markdown("""
        <style>
        .info-card {
            background: linear-gradient(135deg, #f8fafc, #e2e8f0);
            border: 1px solid #cbd5e1;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .badge-blue {
            background: linear-gradient(135deg, #3b82f6, #1d4ed8);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            display: inline-block;
            margin: 0.25rem;
            box-shadow: 0 2px 4px rgba(59, 130, 246, 0.3);
        }
        .badge-light-blue {
            background: linear-gradient(135deg, #0ea5e9, #0284c7);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            display: inline-block;
            margin: 0.25rem;
            box-shadow: 0 2px 4px rgba(14, 165, 233, 0.3);
        }
        .badge-yellow {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            display: inline-block;
            margin: 0.25rem;
            box-shadow: 0 2px 4px rgba(245, 158, 11, 0.3);
        }
        .badge-green {
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            display: inline-block;
            margin: 0.25rem;
            box-shadow: 0 2px 4px rgba(16, 185, 129, 0.3);
        }
        .section-title {
            color: #1e293b;
            font-size: 1.2rem;
            font-weight: 700;
            margin: 1.5rem 0 1rem 0;
            border-bottom: 2px solid #e2e8f0;
            padding-bottom: 0.5rem;
        }
        .field-label {
            color: #475569;
            font-weight: 600;
            font-size: 0.95rem;
            margin-bottom: 0.5rem;
        }
        .field-value {
            color: #1e293b;
            font-size: 1rem;
            margin-bottom: 1rem;
        }
        .status-yes {
            color: #059669;
            font-weight: 600;
        }
        .status-no {
            color: #dc2626;
            font-weight: 600;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Study Identification & Metadata Card
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.markdown('<div class="section-title">üè∑Ô∏è Study Identification & Metadata</div>', unsafe_allow_html=True)
        
        # Study Title
        title = self._safe_get(data, 'study_identification.title', 'Study title not available')
        st.markdown(f'<div class="field-label">üìã Study Title:</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="field-value">{title}</div>', unsafe_allow_html=True)
        
        # Create badges for key identifiers
        badge_col1, badge_col2, badge_col3 = st.columns(3)
        
        with badge_col1:
            acronym = self._safe_get(data, 'study_identification.study_acronym', None)
            if acronym:
                st.markdown(f'<div class="badge-blue">üìù Study Acronym: {acronym}</div>', unsafe_allow_html=True)
        
        with badge_col2:
            abstract_num = self._safe_get(data, 'study_identification.abstract_number', None)
            if abstract_num:
                st.markdown(f'<div class="badge-light-blue">üìÑ Abstract Number: {abstract_num}</div>', unsafe_allow_html=True)
        
        with badge_col3:
            pi = self._safe_get(data, 'study_identification.principal_investigator', None)
            if pi:
                st.markdown(f'<div class="badge-yellow">üë®‚Äç‚öïÔ∏è Principal Investigator: {pi}</div>', unsafe_allow_html=True)
        
        # Additional identifiers
        nct_col, year_col = st.columns(2)
        
        with nct_col:
            nct = self._safe_get(data, 'study_identification.nct_number', None)
            if nct:
                st.markdown(f'<div class="field-label">üîó NCT Number:</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="field-value">{nct}</div>', unsafe_allow_html=True)
        
        with year_col:
            year = self._safe_get(data, 'study_identification.publication_year', None)
            if year:
                st.markdown(f'<div class="field-label">üìÖ Publication Year:</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="field-value">{year}</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Publication Details Card
        conference = self._safe_get(data, 'study_identification.conference', None)
        journal = self._safe_get(data, 'study_identification.journal', None)
        
        if conference or journal:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">üìö Publication Details</div>', unsafe_allow_html=True)
            
            pub_col1, pub_col2 = st.columns(2)
            
            with pub_col1:
                if conference:
                    st.markdown(f'<div class="field-label">üèõÔ∏è Conference:</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="field-value">{conference}</div>', unsafe_allow_html=True)
            
            with pub_col2:
                if journal:
                    st.markdown(f'<div class="field-label">üìñ Journal:</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="field-value">{journal}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Study Design & Methodology Card
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.markdown('<div class="section-title">üî¨ Study Design & Methodology</div>', unsafe_allow_html=True)
        
        # Study Phase prominently displayed
        phase = self._safe_get(data, 'study_design.study_type', 'Not specified')
        st.markdown(f'<div class="field-label">üß™ Study Phase</div>', unsafe_allow_html=True)
        if 'phase' in phase.lower():
            phase_color = "badge-blue" if "3" in phase else "badge-yellow" if "2" in phase else "badge-green"
            st.markdown(f'<div class="{phase_color}">{phase}</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="field-value">{phase}</div>', unsafe_allow_html=True)
        
        # Design characteristics in a grid
        design_col1, design_col2, design_col3 = st.columns(3)
        
        with design_col1:
            randomized = self._safe_get(data, 'study_design.randomized', None)
            st.markdown(f'<div class="field-label">üé≤ Randomized</div>', unsafe_allow_html=True)
            if randomized == True:
                st.markdown('<div class="status-yes">‚úÖ Yes</div>', unsafe_allow_html=True)
            elif randomized == False:
                st.markdown('<div class="status-no">‚ùå No</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value">Not specified</div>', unsafe_allow_html=True)
        
        with design_col2:
            blinded = self._safe_get(data, 'study_design.blinded', None)
            st.markdown(f'<div class="field-label">üëÅÔ∏è Blinded</div>', unsafe_allow_html=True)
            if blinded == True:
                st.markdown('<div class="status-yes">‚úÖ Yes</div>', unsafe_allow_html=True)
            elif blinded == False:
                st.markdown('<div class="status-no">‚ùå No</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value">Not specified</div>', unsafe_allow_html=True)
        
        with design_col3:
            placebo = self._safe_get(data, 'study_design.placebo_controlled', None)
            st.markdown(f'<div class="field-label">üíä Placebo Controlled</div>', unsafe_allow_html=True)
            if placebo == True:
                st.markdown('<div class="status-yes">‚úÖ Yes</div>', unsafe_allow_html=True)
            elif placebo == False:
                st.markdown('<div class="status-no">‚ùå No</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value">Not specified</div>', unsafe_allow_html=True)
        
        # Additional design details
        additional_col1, additional_col2 = st.columns(2)
        
        with additional_col1:
            multicenter = self._safe_get(data, 'study_design.multicenter', None)
            if multicenter is not None:
                st.markdown(f'<div class="field-label">üè• Multicenter</div>', unsafe_allow_html=True)
                if multicenter == True:
                    st.markdown('<div class="status-yes">‚úÖ Yes</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="status-no">‚ùå No</div>', unsafe_allow_html=True)
        
        with additional_col2:
            arms = self._safe_get(data, 'study_design.number_of_arms', None)
            if arms:
                st.markdown(f'<div class="field-label">üî¢ Number of Arms</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="field-value">{arms}</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Primary Endpoints Card
        primary_endpoints = self._safe_get(data, 'study_design.primary_endpoints', None)
        if primary_endpoints:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">üéØ Primary Endpoints</div>', unsafe_allow_html=True)
            
            if isinstance(primary_endpoints, list):
                for endpoint in primary_endpoints:
                    st.markdown(f'<div class="badge-green">{endpoint}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="badge-green">{primary_endpoints}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Secondary Endpoints Card
        secondary_endpoints = self._safe_get(data, 'study_design.secondary_endpoints', None)
        if secondary_endpoints:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">üìä Secondary Endpoints</div>', unsafe_allow_html=True)
            
            endpoint_col1, endpoint_col2, endpoint_col3 = st.columns(3)
            
            if isinstance(secondary_endpoints, list):
                for i, endpoint in enumerate(secondary_endpoints[:6]):  # Show up to 6
                    with [endpoint_col1, endpoint_col2, endpoint_col3][i % 3]:
                        st.markdown(f'<div class="field-label">üìà {endpoint}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="field-label">üìà {secondary_endpoints}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    def _display_results_efficacy_tab(self, data):
        """Display Results & Efficacy tab content with beautiful card-based layout"""
        
        # Primary Efficacy Outcomes Card
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.markdown('<div class="section-title">üéØ Primary Efficacy Outcomes</div>', unsafe_allow_html=True)
        
        efficacy_col1, efficacy_col2 = st.columns(2)
        
        with efficacy_col1:
            # Overall Response Rate
            orr = self._safe_get(data, 'efficacy_outcomes.overall_response_rate')
            st.markdown('<div class="field-label">‚ù§Ô∏è Overall Response Rate</div>', unsafe_allow_html=True)
            if orr:
                if isinstance(orr, dict) and 'value' in orr:
                    orr_value = orr['value']
                    orr_ci = orr.get('ci', '')
                    if orr_ci:
                        st.markdown(f'<div class="field-value" style="color: #3b82f6; font-weight: 600;">{orr_value}% (CI: {orr_ci})</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value" style="color: #3b82f6; font-weight: 600;">{orr_value}%</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="field-value" style="color: #3b82f6; font-weight: 600;">{orr}</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value" style="color: #9ca3af;">N/A%</div>', unsafe_allow_html=True)
        
        with efficacy_col2:
            # Complete Response Rate
            cr = self._safe_get(data, 'efficacy_outcomes.complete_response_rate')
            st.markdown('<div class="field-label">‚≠ê Complete Response Rate</div>', unsafe_allow_html=True)
            if cr:
                if isinstance(cr, dict) and 'value' in cr:
                    cr_value = cr['value']
                    cr_ci = cr.get('ci', '')
                    if cr_ci:
                        st.markdown(f'<div class="field-value" style="color: #10b981; font-weight: 600;">{cr_value}% (CI: {cr_ci})</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value" style="color: #10b981; font-weight: 600;">{cr_value}%</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="field-value" style="color: #10b981; font-weight: 600;">{cr}</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value" style="color: #9ca3af;">N/A%</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Survival Endpoints Card
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        st.markdown('<div class="section-title">‚è±Ô∏è Survival Endpoints</div>', unsafe_allow_html=True)
        
        survival_col1, survival_col2 = st.columns(2)
        
        with survival_col1:
            # Progression-Free Survival
            pfs = self._safe_get(data, 'efficacy_outcomes.progression_free_survival')
            st.markdown('<div class="field-label">üîÑ PFS</div>', unsafe_allow_html=True)
            if pfs:
                if isinstance(pfs, dict):
                    median = pfs.get('median')
                    unit = pfs.get('unit', 'months')
                    ci = pfs.get('ci', '')
                    if median:
                        if ci:
                            st.markdown(f'<div class="field-value" style="color: #0ea5e9; font-weight: 600;">{median} {unit} ({ci})</div>', unsafe_allow_html=True)
                        else:
                            st.markdown(f'<div class="field-value" style="color: #0ea5e9; font-weight: 600;">{median} {unit}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="field-value" style="color: #9ca3af;">N/A months</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="field-value" style="color: #0ea5e9; font-weight: 600;">{pfs}</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value" style="color: #9ca3af;">N/A months (0.31-0.53)</div>', unsafe_allow_html=True)
        
        with survival_col2:
            # Overall Survival
            os = self._safe_get(data, 'efficacy_outcomes.overall_survival')
            st.markdown('<div class="field-label">üìä OS</div>', unsafe_allow_html=True)
            if os:
                if isinstance(os, dict):
                    median = os.get('median')
                    unit = os.get('unit', 'months')
                    ci = os.get('ci', '')
                    if median:
                        if ci:
                            st.markdown(f'<div class="field-value" style="color: #dc2626; font-weight: 600;">{median} {unit} ({ci})</div>', unsafe_allow_html=True)
                        else:
                            st.markdown(f'<div class="field-value" style="color: #dc2626; font-weight: 600;">{median} {unit}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="field-value" style="color: #9ca3af;">Not reached</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="field-value" style="color: #dc2626; font-weight: 600;">{os}</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="field-value" style="color: #9ca3af;">Not reached months (0.40-0.80)</div>', unsafe_allow_html=True)
        
        # Efficacy data confidence
        confidence = self._safe_get(data, 'efficacy_outcomes.confidence_score', 0.95)
        if confidence:
            confidence_percent = confidence * 100 if confidence <= 1 else confidence
            st.markdown(f'<div class="field-label">üî¨ Efficacy data confidence: <span style="color: #10b981; font-weight: 600;">{confidence_percent:.1f}%</span></div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Additional Response Measures Card (if available)
        partial_response = self._safe_get(data, 'efficacy_outcomes.partial_response_rate')
        vgpr = self._safe_get(data, 'efficacy_outcomes.very_good_partial_response')
        stable_disease = self._safe_get(data, 'efficacy_outcomes.stable_disease_rate')
        
        if partial_response or vgpr or stable_disease:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">üìà Additional Response Measures</div>', unsafe_allow_html=True)
            
            response_col1, response_col2, response_col3 = st.columns(3)
            
            with response_col1:
                if partial_response:
                    st.markdown('<div class="field-label">üìä Partial Response Rate</div>', unsafe_allow_html=True)
                    if isinstance(partial_response, dict) and 'value' in partial_response:
                        st.markdown(f'<div class="field-value">{partial_response["value"]}%</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value">{partial_response}</div>', unsafe_allow_html=True)
            
            with response_col2:
                if vgpr:
                    st.markdown('<div class="field-label">‚≠ê VGPR Rate</div>', unsafe_allow_html=True)
                    if isinstance(vgpr, dict) and 'value' in vgpr:
                        st.markdown(f'<div class="field-value">{vgpr["value"]}%</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value">{vgpr}</div>', unsafe_allow_html=True)
            
            with response_col3:
                if stable_disease:
                    st.markdown('<div class="field-label">üìà Stable Disease Rate</div>', unsafe_allow_html=True)
                    if isinstance(stable_disease, dict) and 'value' in stable_disease:
                        st.markdown(f'<div class="field-value">{stable_disease["value"]}%</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value">{stable_disease}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Duration of Response and Time to Response Card (if available)
        duration_response = self._safe_get(data, 'efficacy_outcomes.duration_of_response')
        time_to_response = self._safe_get(data, 'efficacy_outcomes.time_to_response')
        
        if duration_response or time_to_response:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="section-title">‚è∞ Response Kinetics</div>', unsafe_allow_html=True)
            
            kinetics_col1, kinetics_col2 = st.columns(2)
            
            with kinetics_col1:
                if duration_response:
                    st.markdown('<div class="field-label">‚è±Ô∏è Duration of Response</div>', unsafe_allow_html=True)
                    if isinstance(duration_response, dict):
                        median = duration_response.get('median', 'Not reported')
                        unit = duration_response.get('unit', 'months')
                        st.markdown(f'<div class="field-value">{median} {unit}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value">{duration_response}</div>', unsafe_allow_html=True)
            
            with kinetics_col2:
                if time_to_response:
                    st.markdown('<div class="field-label">üöÄ Time to Response</div>', unsafe_allow_html=True)
                    if isinstance(time_to_response, dict):
                        median = time_to_response.get('median', 'Not reported')
                        unit = time_to_response.get('unit', 'months')
                        st.markdown(f'<div class="field-value">{median} {unit}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="field-value">{time_to_response}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    def _display_patient_population_tab(self, data):
        """Display Patient Population tab content"""
        # Enrollment & Age
        st.markdown("### üìä **Enrollment & Age**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            enrollment = self._safe_get(data, 'patient_demographics.total_enrolled', 'Not specified')
            st.markdown("**üë• Total Enrolled:**")
            if enrollment != 'Not specified':
                st.markdown(f":blue[{enrollment} patients]")
            else:
                st.markdown(":gray[Not specified]")
        
        with col2:
            # Gender Distribution
            gender = self._safe_get(data, 'patient_demographics.gender_distribution')
            if gender:
                st.markdown("**‚ö§ Gender Distribution**")
                if isinstance(gender, dict):
                    male = gender.get('male_percentage', 'N/A')
                    female = gender.get('female_percentage', 'N/A')
                    st.markdown(f"Male: {male}%, Female: {female}%")
        
        with col3:
            # Performance Status (ECOG)
            ecog = self._safe_get(data, 'patient_demographics.ecog_performance_status')
            if ecog:
                st.markdown("**‚ö° Performance Status (ECOG)**")
                if isinstance(ecog, dict):
                    for status, percentage in ecog.items():
                        st.markdown(f"ECOG {status}: {percentage}%")
        
        st.markdown("---")
        
        # Disease Characteristics
        st.markdown("### ü©∫ **Disease Characteristics**")
        
        # MM Subtypes
        mm_subtype = self._safe_get(data, 'disease_characteristics.mm_subtype')
        if mm_subtype:
            st.markdown("**üî¨ MM Subtypes:**")
            if isinstance(mm_subtype, list):
                st.markdown(f"‚Ä¢ {', '.join(mm_subtype)}")
            else:
                st.markdown(f"‚Ä¢ {mm_subtype}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # High-Risk Cytogenetics
            high_risk = self._safe_get(data, 'disease_characteristics.high_risk_percentage')
            if high_risk:
                st.markdown("**‚ö†Ô∏è High-Risk Cytogenetics:**")
                st.markdown(f":orange[{high_risk}%]")
            
            # Specific cytogenetic abnormalities
            del_17p = self._safe_get(data, 'disease_characteristics.del_17p_percentage')
            if del_17p:
                st.markdown(f"‚Ä¢ del(17p): {del_17p}%")
            
            t_4_14 = self._safe_get(data, 'disease_characteristics.t_4_14_percentage')
            if t_4_14:
                st.markdown(f"‚Ä¢ t(4;14): {t_4_14}%")
        
        with col2:
            # Disease stage
            stage = self._safe_get(data, 'disease_characteristics.disease_stage')
            if stage:
                st.markdown(f"**üìä Disease Stage:** {stage}")
            
            # Extramedullary disease
            emd = self._safe_get(data, 'disease_characteristics.extramedullary_disease_percentage')
            if emd:
                st.markdown(f"**üîÑ Extramedullary Disease:** {emd}%")
        
        # Data confidence
        confidence = self._safe_get(data, 'patient_demographics.confidence_score', 0.85)
        st.markdown(f"**üìä Data confidence:** {confidence*100:.0f}%")
    
    def _display_treatment_regimens_tab(self, data):
        """Display Treatment Regimens tab content"""
        st.markdown("### üíä **Treatment Regimens & Drug Information**")
        
        treatment_regimens = self._safe_get(data, 'treatment_regimens', [])
        
        if not treatment_regimens:
            st.info("No treatment regimen details available")
            return
        
        for idx, regimen in enumerate(treatment_regimens):
            st.markdown(f"#### **Regimen {idx + 1}: {self._safe_get(regimen, 'regimen_name', f'Regimen {idx + 1}')}**")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                arm = self._safe_get(regimen, 'arm_designation', 'Not specified')
                st.markdown(f"**üè∑Ô∏è Arm:** {arm}")
            
            with col2:
                cycle_length = self._safe_get(regimen, 'cycle_length', 'Not specified')
                st.markdown(f"**‚è∞ Cycle Length:** {cycle_length}")
            
            with col3:
                total_cycles = self._safe_get(regimen, 'total_planned_cycles', 'Not specified')
                st.markdown(f"**üìä Planned Cycles:** {total_cycles}")
            
            with col4:
                outpatient = self._safe_get(regimen, 'outpatient_administration')
                if outpatient == True:
                    st.markdown("**üè† Outpatient:** :green[‚úÖ Yes]")
                elif outpatient == False:
                    st.markdown("**üè† Outpatient:** :red[‚ùå No]")
            
            # Individual Drug Details
            drugs = self._safe_get(regimen, 'drugs', [])
            if drugs:
                st.markdown("##### üíâ **Individual Drug Details**")
                
                # Create a nice table for drugs
                drug_data = []
                for drug in drugs:
                    drug_data.append({
                        "Drug Name": self._safe_get(drug, 'name', 'Unknown'),
                        "Dose": self._safe_get(drug, 'dose', 'Not specified'),
                        "Route": self._safe_get(drug, 'route', 'Not specified'),
                        "Schedule": self._safe_get(drug, 'schedule', 'Not specified'),
                        "Days": self._safe_get(drug, 'duration', 'Not specified')
                    })
                
                if drug_data:
                    st.table(drug_data)
            
            # Administration Details
            st.markdown("##### üè• **Administration Details**")
            col1, col2 = st.columns(2)
            
            with col1:
                dose_reductions = self._safe_get(regimen, 'dose_reductions_allowed')
                if dose_reductions == True:
                    st.markdown("**üíä Dose Reductions:** :green[Allowed]")
                elif dose_reductions == False:
                    st.markdown("**üíä Dose Reductions:** :red[Not Allowed]")
            
            with col2:
                hospitalization = self._safe_get(regimen, 'hospitalization_required')
                if hospitalization == True:
                    st.markdown("**üè• Hospitalization:** :red[Required]")
                elif hospitalization == False:
                    st.markdown("**üè• Hospitalization:** :green[Not Required]")
            
            # Extraction Confidence
            confidence = self._safe_get(regimen, 'confidence_score', 0.85)
            st.markdown(f"**üü¢ Extraction Confidence:** {confidence*100:.0f}%")
            
            if idx < len(treatment_regimens) - 1:
                st.markdown("---")
    
    def _display_safety_profile_tab(self, data):
        """Display Safety Profile tab content"""
        st.markdown("### ‚ö†Ô∏è **Safety Profile & Adverse Events**")
        
        # Safety Population
        safety_pop = self._safe_get(data, 'safety_profile.safety_population')
        if safety_pop:
            st.markdown(f"**üë• Safety Population:** {safety_pop} patients")
        
        st.markdown("---")
        
        # Grade 3-4 Adverse Events
        grade_3_4_aes = self._safe_get(data, 'safety_profile.grade_3_4_aes')
        if grade_3_4_aes:
            st.markdown("### üî¥ **Grade 3-4 Adverse Events**")
            
            if isinstance(grade_3_4_aes, list) and grade_3_4_aes:
                col1, col2, col3 = st.columns(3)
                for i, ae in enumerate(grade_3_4_aes[:9]):  # Show up to 9 AEs
                    with [col1, col2, col3][i % 3]:
                        event_name = ae.get('event', 'Unknown AE') if isinstance(ae, dict) else str(ae)
                        percentage = ae.get('percentage', 'N/A') if isinstance(ae, dict) else 'N/A'
                        
                        # Color code based on severity
                        if isinstance(percentage, (int, float)):
                            if percentage >= 20:
                                color = "red"
                            elif percentage >= 10:
                                color = "orange" 
                            else:
                                color = "green"
                        else:
                            color = "gray"
                        
                        st.markdown(f"**{event_name}:** :{color}[{percentage}%]")
        
        st.markdown("---")
        
        # Treatment Modifications
        st.markdown("### üìä **Treatment Modifications**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            dose_reductions = self._safe_get(data, 'safety_profile.dose_reductions')
            if dose_reductions:
                st.markdown(f"**üíä Dose Reductions:** {dose_reductions}%")
        
        with col2:
            delays = self._safe_get(data, 'safety_profile.treatment_delays')
            if delays:
                st.markdown(f"**‚è∏Ô∏è Treatment Delays:** {delays}%")
        
        with col3:
            discontinuations = self._safe_get(data, 'safety_profile.discontinuations')
            if discontinuations:
                st.markdown(f"**üõë Discontinuations:** {discontinuations}%")
        
        # Serious Adverse Events
        serious_aes = self._safe_get(data, 'safety_profile.serious_aes')
        if serious_aes:
            st.markdown("---")
            st.markdown("### üö® **Serious Adverse Events**")
            if isinstance(serious_aes, list):
                for ae in serious_aes:
                    if isinstance(ae, dict):
                        event = ae.get('event', 'Unknown')
                        percentage = ae.get('percentage', 'N/A')
                        st.markdown(f"‚Ä¢ **{event}:** {percentage}%")
            else:
                st.markdown(f"‚Ä¢ {serious_aes}")
        
        # Deaths
        deaths = self._safe_get(data, 'safety_profile.total_deaths') or self._safe_get(data, 'safety_profile.treatment_related_deaths')
        if deaths:
            st.markdown("---")
            st.markdown("### ‚ò†Ô∏è **Mortality**")
            st.markdown(f"**Total Deaths:** {deaths}")
        
        # Safety Confidence
        confidence = self._safe_get(data, 'safety_profile.confidence_score', 0.85)
        st.markdown("---")
        st.markdown(f"**üü¢ Safety data confidence:** {confidence*100:.0f}%")
    def _display_study_identification_comprehensive(self, data):
        """Display all 8 study identification fields"""
        st.markdown("### üìÑ **Study Identification (8 Fields)**")
        
        study_id_data = []
        fields = [
            ("Full Title", "study_identification.title", "Primary identifier for the clinical study"),
            ("Study Acronym", "study_identification.study_acronym", "Short name or acronym for the study"),
            ("NCT Number", "study_identification.nct_number", "ClinicalTrials.gov registry identifier"),
            ("Abstract Number", "study_identification.abstract_number", "Conference abstract reference number"),
            ("Study Group/Sponsor", "study_identification.study_group", "Sponsoring organization or study group"),
            ("Principal Investigator", "study_identification.principal_investigator", "Lead investigator for the study"),
            ("Publication Year", "study_identification.publication_year", "Year of publication or presentation"),
            ("Conference Name", "study_identification.conference_name", "Conference where study was presented")
        ]
        
        for field_name, field_path, description in fields:
            value = self._safe_get(data, field_path)
            display_value = str(value) if value is not None else "Not specified"
            
            study_id_data.append({
                "Field": field_name,
                "Value": display_value,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Data Type": type(value).__name__ if value is not None else "None"
            })
        
        st.dataframe(pd.DataFrame(study_id_data), use_container_width=True, hide_index=True)
    
    def _display_study_design_comprehensive(self, data):
        """Display all 17 study design fields"""
        st.markdown("### üî¨ **Study Design Details (17 Fields)**")
        
        design_data = []
        design_fields = [
            ("Study Type", "study_design.study_type.value", "Phase or type of clinical study"),
            ("Trial Phase", "study_design.trial_phase", "Specific phase designation"),
            ("Randomized", "study_design.randomized", "Whether study uses randomization"),
            ("Blinded", "study_design.blinded", "Whether study is blinded"),
            ("Placebo Controlled", "study_design.placebo_controlled", "Whether study includes placebo control"),
            ("Multicenter", "study_design.multicenter", "Whether study involves multiple centers"),
            ("International", "study_design.international", "Whether study is international"),
            ("Number of Arms", "study_design.number_of_arms", "Number of treatment arms"),
            ("Randomization Ratio", "study_design.randomization_ratio", "Ratio for randomization (e.g., 1:1, 2:1)"),
            ("Number of Centers", "study_design.number_of_centers", "Total participating centers"),
            ("Countries", "study_design.countries", "Countries where study was conducted"),
            ("Enrollment Period", "study_design.enrollment_period", "Patient enrollment timeframe"),
            ("Follow-up Duration", "study_design.follow_up_duration", "Median follow-up duration"),
            ("Data Cutoff Date", "study_design.data_cutoff_date", "Date of data analysis cutoff"),
            ("Primary Endpoints", "study_design.primary_endpoints", "Primary study endpoints"),
            ("Secondary Endpoints", "study_design.secondary_endpoints", "Secondary study endpoints"),
            ("Exploratory Endpoints", "study_design.exploratory_endpoints", "Exploratory endpoints")
        ]
        
        for field_name, field_path, description in design_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, list):
                display_value = ", ".join([str(v) for v in value]) if value else "Not specified"
            elif isinstance(value, bool):
                display_value = "Yes" if value else "No"
            else:
                display_value = str(value) if value is not None else "Not specified"
            
            design_data.append({
                "Design Element": field_name,
                "Value": display_value,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Data Type": type(value).__name__ if value is not None else "None"
            })
        
        st.dataframe(pd.DataFrame(design_data), use_container_width=True, hide_index=True)
    
    def _display_patient_demographics_comprehensive(self, data):
        """Display all 17 patient demographic fields"""
        st.markdown("### üë• **Patient Demographics (17 Fields)**")
        
        demo_data = []
        demo_fields = [
            ("Total Enrolled", "patient_demographics.total_enrolled", "patients", "Total number of patients enrolled"),
            ("Evaluable Patients", "patient_demographics.evaluable_patients", "patients", "Number of evaluable patients"),
            ("Safety Population", "patient_demographics.safety_population", "patients", "Safety analysis population"),
            ("ITT Population", "patient_demographics.itt_population", "patients", "Intent-to-treat population"),
            ("Median Age", "patient_demographics.median_age", "years", "Median age of enrolled patients"),
            ("Mean Age", "patient_demographics.mean_age", "years", "Mean age of enrolled patients"),
            ("Age Range", "patient_demographics.age_range", "years", "Age range of enrolled patients"),
            ("Elderly Percentage (‚â•65)", "patient_demographics.elderly_percentage", "%", "Percentage of elderly patients"),
            ("Very Elderly Percentage (‚â•75)", "patient_demographics.very_elderly_percentage", "%", "Percentage of very elderly patients"),
            ("Male Percentage", "patient_demographics.male_percentage", "%", "Percentage of male patients"),
            ("Female Percentage", "patient_demographics.female_percentage", "%", "Percentage of female patients"),
            ("Race Distribution", "patient_demographics.race_distribution", "breakdown", "Racial/ethnic distribution"),
            ("ECOG 0 Percentage", "patient_demographics.ecog_0_percentage", "%", "Patients with ECOG PS 0"),
            ("ECOG 1 Percentage", "patient_demographics.ecog_1_percentage", "%", "Patients with ECOG PS 1"),
            ("ECOG ‚â•2 Percentage", "patient_demographics.ecog_2_plus_percentage", "%", "Patients with ECOG PS ‚â•2"),
            ("Karnofsky Median", "patient_demographics.karnofsky_median", "score", "Median Karnofsky performance score"),
            ("High Frailty Score", "patient_demographics.frailty_score_high", "%", "Percentage with high frailty scores")
        ]
        
        for field_name, field_path, unit, description in demo_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, dict):
                display_value = json.dumps(value, indent=1)
            elif value is not None:
                display_value = f"{value} {unit}" if unit != "breakdown" else str(value)
            else:
                display_value = "Not reported"
            
            demo_data.append({
                "Demographic": field_name,
                "Value": display_value,
                "Unit": unit,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Clinical Relevance": self._get_demo_relevance(field_name)
            })
        
        st.dataframe(pd.DataFrame(demo_data), use_container_width=True, hide_index=True)
    
    def _display_disease_characteristics_comprehensive(self, data):
        """Display all 18 disease characteristic fields"""
        st.markdown("### ü©∫ **Disease Characteristics (18 Fields)**")
        
        disease_data = []
        disease_fields = [
            ("MM Subtype", "disease_characteristics.mm_subtype", "classification", "Multiple myeloma subtype classification"),
            ("Disease Stage", "disease_characteristics.disease_stage", "stage", "Disease staging (ISS, R-ISS)"),
            ("High Risk Percentage", "disease_characteristics.high_risk_percentage", "%", "Percentage of high-risk patients"),
            ("Standard Risk Percentage", "disease_characteristics.standard_risk_percentage", "%", "Percentage of standard-risk patients"),
            ("Ultra High Risk Percentage", "disease_characteristics.ultra_high_risk_percentage", "%", "Percentage of ultra high-risk patients"),
            ("Cytogenetic Abnormalities", "disease_characteristics.cytogenetic_abnormalities", "list", "List of cytogenetic abnormalities"),
            ("del(17p) Percentage", "disease_characteristics.del_17p_percentage", "%", "Frequency of del(17p) abnormality"),
            ("t(4;14) Percentage", "disease_characteristics.t_4_14_percentage", "%", "Frequency of t(4;14) translocation"),
            ("t(14;16) Percentage", "disease_characteristics.t_14_16_percentage", "%", "Frequency of t(14;16) translocation"),
            ("1q Amplification Percentage", "disease_characteristics.amp_1q_percentage", "%", "Frequency of 1q amplification"),
            ("Extramedullary Disease", "disease_characteristics.extramedullary_disease_percentage", "%", "Presence of extramedullary disease"),
            ("Plasma Cell Leukemia", "disease_characteristics.plasma_cell_leukemia_percentage", "%", "Presence of plasma cell leukemia"),
            ("Amyloidosis Percentage", "disease_characteristics.amyloidosis_percentage", "%", "Presence of amyloidosis"),
            ("Elevated LDH", "disease_characteristics.ldh_elevated_percentage", "%", "Patients with elevated LDH"),
            ("High Œ≤2-Microglobulin", "disease_characteristics.beta2_microglobulin_high", "%", "Patients with high Œ≤2-microglobulin"),
            ("Low Albumin", "disease_characteristics.albumin_low_percentage", "%", "Patients with low albumin"),
            ("Renal Impairment", "disease_characteristics.renal_impairment_percentage", "%", "Patients with renal impairment"),
            ("Biomarker Results", "disease_characteristics.biomarker_results", "data", "Biomarker analysis results")
        ]
        
        for field_name, field_path, unit, description in disease_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, list):
                if field_name == "MM Subtype":
                    display_value = ", ".join([str(v) for v in value]) if value else "Not specified"
                else:
                    display_value = json.dumps(value, indent=1) if value else "Not reported"
            elif isinstance(value, dict):
                display_value = json.dumps(value, indent=1)
            elif value is not None:
                display_value = f"{value} {unit}" if unit not in ["classification", "stage", "list", "data"] else str(value)
            else:
                display_value = "Not reported"
            
            disease_data.append({
                "Disease Characteristic": field_name,
                "Value": display_value,
                "Unit": unit,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Risk Assessment": self._get_risk_level(field_name, value)
            })
        
        st.dataframe(pd.DataFrame(disease_data), use_container_width=True, hide_index=True)
    
    def _display_treatment_history_comprehensive(self, data):
        """Display all 19 treatment history fields"""
        st.markdown("### üíä **Treatment History (19 Fields)**")
        
        treatment_data = []
        treatment_fields = [
            ("Line of Therapy", "treatment_history.line_of_therapy", "line", "Current line of therapy"),
            ("Treatment Setting", "treatment_history.treatment_setting", "setting", "Treatment setting (NDMM/RRMM)"),
            ("Median Prior Therapies", "treatment_history.median_prior_therapies", "number", "Median number of prior therapies"),
            ("Prior Therapy Range", "treatment_history.prior_therapy_range", "range", "Range of prior therapies"),
            ("Heavily Pretreated (‚â•3)", "treatment_history.heavily_pretreated_percentage", "%", "Patients with ‚â•3 prior therapies"),
            ("Prior Therapies List", "treatment_history.prior_therapies", "list", "List of specific prior therapies"),
            ("Lenalidomide Exposed", "treatment_history.lenalidomide_exposed_percentage", "%", "Prior lenalidomide exposure"),
            ("Lenalidomide Refractory", "treatment_history.lenalidomide_refractory_percentage", "%", "Lenalidomide-refractory patients"),
            ("Pomalidomide Exposed", "treatment_history.pomalidomide_exposed_percentage", "%", "Prior pomalidomide exposure"),
            ("Bortezomib Exposed", "treatment_history.bortezomib_exposed_percentage", "%", "Prior bortezomib exposure"),
            ("Carfilzomib Exposed", "treatment_history.carfilzomib_exposed_percentage", "%", "Prior carfilzomib exposure"),
            ("Daratumumab Exposed", "treatment_history.daratumumab_exposed_percentage", "%", "Prior daratumumab exposure"),
            ("Daratumumab Refractory", "treatment_history.daratumumab_refractory_percentage", "%", "Daratumumab-refractory patients"),
            ("Prior Autologous SCT", "treatment_history.prior_autologous_sct_percentage", "%", "Prior autologous stem cell transplant"),
            ("Prior Allogeneic SCT", "treatment_history.prior_allogeneic_sct_percentage", "%", "Prior allogeneic stem cell transplant"),
            ("Double Refractory", "treatment_history.double_refractory_percentage", "%", "Double-refractory patients"),
            ("Triple Refractory", "treatment_history.triple_refractory_percentage", "%", "Triple-refractory patients"),
            ("Penta Refractory", "treatment_history.penta_refractory_percentage", "%", "Penta-refractory patients"),
            ("Time Since Diagnosis", "treatment_history.time_since_diagnosis_median", "months", "Median time since initial diagnosis"),
            ("Time Since Last Therapy", "treatment_history.time_since_last_therapy_median", "months", "Median time since last therapy")
        ]
        
        for field_name, field_path, unit, description in treatment_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, list):
                display_value = json.dumps(value, indent=1) if value else "Not reported"
            elif value is not None:
                display_value = f"{value} {unit}" if unit not in ["line", "setting", "list", "range"] else str(value)
            else:
                display_value = "Not reported"
            
            treatment_data.append({
                "Treatment History": field_name,
                "Value": display_value,
                "Unit": unit,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Impact": self._get_treatment_impact(field_name, value)
            })
        
        st.dataframe(pd.DataFrame(treatment_data), use_container_width=True, hide_index=True)
    
    def _display_treatment_regimens_comprehensive(self, data):
        """Display comprehensive treatment regimen details"""
        st.markdown("### üß¨ **Treatment Regimens & Drug Details**")
        
        treatment_regimens = self._safe_get(data, 'treatment_regimens') or []
        if treatment_regimens:
            for idx, regimen in enumerate(treatment_regimens):
                st.markdown(f"#### üíä **Regimen {idx + 1}**")
                
                # Regimen overview (14 fields per regimen)
                regimen_overview = []
                regimen_fields = [
                    ("Regimen Name", "regimen_name", "Name or acronym of treatment regimen"),
                    ("Arm Designation", "arm_designation", "Treatment arm designation (e.g., Arm A, Experimental)"),
                    ("Novel Regimen", "is_novel_regimen", "Whether this is a novel treatment combination"),
                    ("Drug Classes", "drug_classes", "Classes of drugs in the regimen"),
                    ("Mechanism of Action", "mechanism_of_action", "Mechanisms of action for the drugs"),
                    ("Cycle Length (days)", "cycle_length", "Length of each treatment cycle"),
                    ("Total Planned Cycles", "total_planned_cycles", "Total number of planned treatment cycles"),
                    ("Treatment Until Progression", "treatment_until_progression", "Whether treatment continues until progression"),
                    ("Dose Reductions Allowed", "dose_reductions_allowed", "Whether dose reductions are permitted"),
                    ("Growth Factor Support", "growth_factor_support", "Growth factor support requirements"),
                    ("Premedications", "premedications", "Required premedications"),
                    ("Outpatient Administration", "outpatient_administration", "Whether treatment is given as outpatient"),
                    ("Hospitalization Required", "hospitalization_required", "Whether hospitalization is required"),
                    ("Confidence Score", "confidence_score", "Extraction confidence for this regimen")
                ]
                
                for field_name, field_key, description in regimen_fields:
                    if isinstance(regimen, dict):
                        value = regimen.get(field_key)
                    else:
                        value = getattr(regimen, field_key, None)
                    
                    if isinstance(value, list):
                        display_value = ", ".join([str(v) for v in value]) if value else "Not specified"
                    elif isinstance(value, bool):
                        display_value = "Yes" if value else "No"
                    else:
                        display_value = str(value) if value is not None else "Not specified"
                    
                    regimen_overview.append({
                        "Regimen Detail": field_name,
                        "Value": display_value,
                        "Description": description,
                        "Available": "‚úÖ" if value is not None else "‚ùå"
                    })
                
                st.dataframe(pd.DataFrame(regimen_overview), use_container_width=True, hide_index=True)
                
                # Individual drugs
                if isinstance(regimen, dict):
                    drugs = regimen.get('drugs', [])
                else:
                    drugs = getattr(regimen, 'drugs', [])
                
                if drugs:
                    st.markdown("##### üíâ **Individual Drug Details**")
                    drug_data = []
                    for drug_idx, drug in enumerate(drugs):
                        if isinstance(drug, dict):
                            drug_data.append({
                                "Drug #": drug_idx + 1,
                                "Drug Name": drug.get('name', 'Unknown'),
                                "Dose": drug.get('dose', 'Not specified'),
                                "Route": drug.get('route', 'Not specified'),
                                "Schedule": drug.get('schedule', 'Not specified'),
                                "Form": drug.get('form', 'Not specified'),
                                "Duration": drug.get('duration', 'Not specified')
                            })
                        else:
                            drug_data.append({
                                "Drug #": drug_idx + 1,
                                "Drug Name": getattr(drug, 'name', 'Unknown'),
                                "Dose": getattr(drug, 'dose', 'Not specified'),
                                "Route": getattr(drug, 'route', 'Not specified'),
                                "Schedule": getattr(drug, 'schedule', 'Not specified'),
                                "Form": getattr(drug, 'form', 'Not specified'),
                                "Duration": getattr(drug, 'duration', 'Not specified')
                            })
                    
                    st.dataframe(pd.DataFrame(drug_data), use_container_width=True, hide_index=True)
                
                st.markdown("---")
        else:
            st.info("No treatment regimen details available")
    
    def _display_efficacy_outcomes_comprehensive(self, data):
        """Display all 18 efficacy outcome fields"""
        st.markdown("### üìà **Efficacy Outcomes (18 Fields)**")
        
        efficacy_data = []
        efficacy_fields = [
            ("Overall Response Rate", "efficacy_outcomes.overall_response_rate", "response", "Overall response rate with confidence intervals"),
            ("Complete Response Rate", "efficacy_outcomes.complete_response_rate", "response", "Complete response rate"),
            ("VGPR Rate", "efficacy_outcomes.very_good_partial_response_rate", "response", "Very good partial response rate"),
            ("Partial Response Rate", "efficacy_outcomes.partial_response_rate", "response", "Partial response rate"),
            ("Stable Disease Rate", "efficacy_outcomes.stable_disease_rate", "response", "Stable disease rate"),
            ("Progressive Disease Rate", "efficacy_outcomes.progressive_disease_rate", "response", "Progressive disease rate"),
            ("Clinical Benefit Rate", "efficacy_outcomes.clinical_benefit_rate", "response", "Clinical benefit rate (CR+VGPR+PR+SD)"),
            ("Progression-Free Survival", "efficacy_outcomes.progression_free_survival", "survival", "Progression-free survival data"),
            ("Overall Survival", "efficacy_outcomes.overall_survival", "survival", "Overall survival data"),
            ("Event-Free Survival", "efficacy_outcomes.event_free_survival", "survival", "Event-free survival data"),
            ("Time to Next Treatment", "efficacy_outcomes.time_to_next_treatment", "survival", "Time to next treatment"),
            ("Time to Response", "efficacy_outcomes.time_to_response", "timing", "Time to first response"),
            ("Duration of Response", "efficacy_outcomes.duration_of_response", "timing", "Duration of response"),
            ("Time to Progression", "efficacy_outcomes.time_to_progression", "timing", "Time to progression"),
            ("MRD Negative Rate", "efficacy_outcomes.mrd_negative_rate", "response", "Minimal residual disease negativity rate"),
            ("MRD Method", "efficacy_outcomes.mrd_method", "method", "Method used for MRD detection"),
            ("Stringent CR Rate", "efficacy_outcomes.stringent_cr_rate", "response", "Stringent complete response rate"),
            ("Subgroup Analyses", "efficacy_outcomes.subgroup_analyses", "analyses", "Subgroup efficacy analyses")
        ]
        
        for field_name, field_path, category, description in efficacy_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, dict):
                # Handle response/survival data structures
                if 'value' in value:
                    display_value = f"{value['value']}%"
                    if value.get('ci'):
                        display_value += f" (CI: {value['ci']})"
                elif 'median' in value:
                    display_value = f"{value['median']} {value.get('unit', 'months')}"
                    if value.get('ci'):
                        display_value += f" (CI: {value['ci']})"
                else:
                    display_value = json.dumps(value, indent=1)
            elif isinstance(value, list):
                display_value = json.dumps(value, indent=1) if value else "Not reported"
            elif value is not None:
                display_value = str(value)
            else:
                display_value = "Not reported"
            
            efficacy_data.append({
                "Efficacy Endpoint": field_name,
                "Value": display_value,
                "Category": category,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Clinical Priority": self._get_endpoint_priority(field_name)
            })
        
        st.dataframe(pd.DataFrame(efficacy_data), use_container_width=True, hide_index=True)
    
    def _display_safety_profile_comprehensive(self, data):
        """Display all 17 safety profile fields"""
        st.markdown("### ‚ö†Ô∏è **Safety Profile (17 Fields)**")
        
        safety_data = []
        safety_fields = [
            ("Safety Population", "safety_profile.safety_population", "count", "Number of patients in safety analysis"),
            ("Median Treatment Duration", "safety_profile.median_treatment_duration", "months", "Median duration of treatment"),
            ("Median Cycles Received", "safety_profile.median_cycles_received", "cycles", "Median number of treatment cycles"),
            ("Completion Rate", "safety_profile.completion_rate", "%", "Treatment completion rate"),
            ("Any Grade AEs", "safety_profile.any_grade_aes", "events", "Any grade adverse events"),
            ("Grade 3-4 AEs", "safety_profile.grade_3_4_aes", "events", "Grade 3-4 adverse events"),
            ("Grade 5 AEs", "safety_profile.grade_5_aes", "events", "Grade 5 (fatal) adverse events"),
            ("Serious AEs", "safety_profile.serious_aes", "events", "Serious adverse events"),
            ("Treatment-Related AEs", "safety_profile.treatment_related_aes", "events", "Treatment-related adverse events"),
            ("Hematologic AEs", "safety_profile.hematologic_aes", "events", "Hematologic toxicities"),
            ("Infections", "safety_profile.infections", "events", "Infection rates and types"),
            ("Secondary Malignancies", "safety_profile.secondary_malignancies", "events", "Secondary cancer occurrences"),
            ("Dose Reductions", "safety_profile.dose_reductions", "modifications", "Dose reduction rates and reasons"),
            ("Treatment Delays", "safety_profile.treatment_delays", "modifications", "Treatment delay rates"),
            ("Discontinuations", "safety_profile.discontinuations", "modifications", "Treatment discontinuation rates"),
            ("Treatment-Related Deaths", "safety_profile.treatment_related_deaths", "count", "Deaths attributed to treatment"),
            ("Total Deaths", "safety_profile.total_deaths", "count", "Total deaths during study period")
        ]
        
        for field_name, field_path, category, description in safety_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, list):
                if value:
                    if category == "events":
                        # Format AE list nicely
                        ae_summary = []
                        for ae in value[:5]:  # Show top 5
                            if isinstance(ae, dict):
                                event_name = ae.get('event', 'Unknown AE')
                                percentage = ae.get('percentage', 'N/A')
                                ae_summary.append(f"{event_name}: {percentage}%")
                        display_value = "; ".join(ae_summary)
                        if len(value) > 5:
                            display_value += f" (+{len(value) - 5} more)"
                    else:
                        display_value = json.dumps(value, indent=1)
                else:
                    display_value = "Not reported"
            elif isinstance(value, dict):
                display_value = json.dumps(value, indent=1)
            elif value is not None:
                if category in ["months", "cycles", "%"]:
                    display_value = f"{value} {category}"
                else:
                    display_value = str(value)
            else:
                display_value = "Not reported"
            
            safety_data.append({
                "Safety Parameter": field_name,
                "Value": display_value,
                "Category": category,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå",
                "Severity": self._get_safety_severity(field_name, value)
            })
        
        st.dataframe(pd.DataFrame(safety_data), use_container_width=True, hide_index=True)
    
    def _display_qol_and_statistics_comprehensive(self, data):
        """Display Quality of Life (5 fields) and Statistical Analysis (8 fields)"""
        
        # Quality of Life (5 fields)
        qol = self._safe_get(data, 'quality_of_life')
        if qol:
            st.markdown("### üí´ **Quality of Life Measures (5 Fields)**")
            qol_data = []
            qol_fields = [
                ("QoL Instruments", "qol_instruments", "Quality of life assessment instruments used"),
                ("Baseline QoL Scores", "baseline_qol_scores", "Baseline quality of life scores"),
                ("QoL Improvement Rate", "qol_improvement_rate", "Rate of quality of life improvement"),
                ("Symptom Relief Rate", "symptom_relief_rate", "Rate of symptom relief"),
                ("Time to QoL Improvement", "time_to_qol_improvement", "Time to quality of life improvement")
            ]
            
            for field_name, field_key, description in qol_fields:
                if isinstance(qol, dict):
                    value = qol.get(field_key)
                else:
                    value = getattr(qol, field_key, None)
                
                if isinstance(value, list):
                    display_value = ", ".join([str(v) for v in value]) if value else "Not reported"
                elif isinstance(value, dict):
                    display_value = json.dumps(value, indent=1)
                elif value is not None:
                    display_value = str(value)
                else:
                    display_value = "Not reported"
                
                qol_data.append({
                    "QoL Measure": field_name,
                    "Value": display_value,
                    "Description": description,
                    "Available": "‚úÖ" if value is not None else "‚ùå"
                })
            
            st.dataframe(pd.DataFrame(qol_data), use_container_width=True, hide_index=True)
        else:
            st.info("No Quality of Life data available")
        
        # Statistical Analysis (8 fields)
        st.markdown("### üìà **Statistical Analysis Details (8 Fields)**")
        stats_data = []
        stats_fields = [
            ("Primary Analysis Method", "statistical_analysis.primary_analysis_method", "Primary statistical analysis method"),
            ("Significance Level", "statistical_analysis.significance_level", "Statistical significance level (alpha)"),
            ("Power Calculation", "statistical_analysis.power_calculation", "Statistical power calculation details"),
            ("Sample Size Rationale", "statistical_analysis.sample_size_rationale", "Sample size calculation rationale"),
            ("Survival Analysis Method", "statistical_analysis.survival_analysis_method", "Method used for survival analysis"),
            ("Censoring Details", "statistical_analysis.censoring_details", "Data censoring information"),
            ("Hazard Ratios", "statistical_analysis.hazard_ratios", "Hazard ratios with confidence intervals"),
            ("P-values", "statistical_analysis.p_values", "Key statistical p-values")
        ]
        
        for field_name, field_path, description in stats_fields:
            value = self._safe_get(data, field_path)
            
            if isinstance(value, list):
                display_value = json.dumps(value, indent=1) if value else "Not reported"
            elif isinstance(value, dict):
                display_value = json.dumps(value, indent=1)
            elif value is not None:
                display_value = str(value)
            else:
                display_value = "Not reported"
            
            stats_data.append({
                "Statistical Parameter": field_name,
                "Value": display_value,
                "Description": description,
                "Available": "‚úÖ" if value is not None else "‚ùå"
            })
        
        st.dataframe(pd.DataFrame(stats_data), use_container_width=True, hide_index=True)


# Helper methods for comprehensive display - these were missing and causing attribute errors
    def _get_demo_relevance(self, field_name: str) -> str:
        """Get clinical relevance level for demographic fields"""
        critical_fields = ["Total Enrolled", "Median Age", "ECOG"]
        high_fields = ["Male Percentage", "Elderly Percentage", "Safety Population", "ITT Population"]
        medium_fields = ["Race Distribution", "Karnofsky", "Frailty"]
        
        if any(cf in field_name for cf in critical_fields):
            return "Critical"
        elif any(hf in field_name for hf in high_fields):
            return "High"
        elif any(mf in field_name for mf in medium_fields):
            return "Medium"
        else:
            return "Standard"
    
    def _get_risk_level(self, field_name: str, value) -> str:
        """Get risk assessment for disease characteristics"""
        if "High Risk" in field_name or "Ultra High" in field_name:
            return "High Impact"
        elif any(term in field_name for term in ["del(17p)", "t(4;14)", "t(14;16)", "1q Amplification"]):
            return "Cytogenetic Risk"
        elif "Extramedullary" in field_name or "Leukemia" in field_name or "Amyloidosis" in field_name:
            return "Disease Severity"
        elif "LDH" in field_name or "Microglobulin" in field_name or "Albumin" in field_name:
            return "Laboratory Marker"
        elif "Biomarker" in field_name:
            return "Biomarker Data"
        else:
            return "Standard"
    
    def _get_treatment_impact(self, field_name: str, value) -> str:
        """Get treatment impact assessment"""
        if "Refractory" in field_name:
            if "Penta" in field_name:
                return "Extreme Resistance"
            elif "Triple" in field_name:
                return "High Resistance"
            elif "Double" in field_name:
                return "Moderate Resistance"
            else:
                return "Drug Resistance"
        elif "Exposed" in field_name:
            return "Previous Treatment"
        elif "SCT" in field_name:
            return "Transplant History"
        elif "Heavily Pretreated" in field_name:
            return "Treatment Burden"
        elif "Line of Therapy" in field_name:
            return "Treatment Sequence"
        elif "Time Since" in field_name:
            return "Treatment Timing"
        else:
            return "Treatment Context"
    
    def _get_endpoint_priority(self, field_name: str) -> str:
        """Get clinical priority for efficacy endpoints"""
        primary_endpoints = ["Overall Response Rate", "Progression-Free Survival", "Overall Survival"]
        high_priority = ["Complete Response Rate", "VGPR Rate", "MRD Negative Rate", "Stringent CR Rate"]
        survival_endpoints = ["Event-Free Survival", "Time to Next Treatment", "Duration of Response"]
        
        if field_name in primary_endpoints:
            return "Primary"
        elif field_name in high_priority:
            return "High"
        elif field_name in survival_endpoints or "Survival" in field_name:
            return "High"
        elif "Response" in field_name or "Disease" in field_name:
            return "Secondary"
        elif "Time to" in field_name or "Duration" in field_name:
            return "Timing"
        elif "Subgroup" in field_name or "Method" in field_name:
            return "Exploratory"
        else:
            return "Secondary"
    
    def _get_safety_severity(self, field_name: str, value) -> str:
        """Get safety severity assessment"""
        if "Grade 5" in field_name or "Deaths" in field_name:
            return "Critical"
        elif "Grade 3-4" in field_name:
            return "High"
        elif "Serious" in field_name:
            return "High"
        elif "Treatment-Related" in field_name:
            return "Moderate"
        elif "Discontinuation" in field_name:
            return "Moderate"
        elif "Dose Reduction" in field_name or "Treatment Delay" in field_name:
            return "Moderate"
        elif "Hematologic" in field_name or "Infection" in field_name:
            return "Moderate"
        elif "Secondary Malignancies" in field_name:
            return "High"
        elif "Any Grade" in field_name:
            return "Standard"
        else:
            return "Standard"

    def _show_individual_study_tabs(self, data, categorization, index):
        """Show individual study tabs with beautiful card-based detailed information"""
        st.markdown(f"### üìã Study {index + 1}: {data.study_identification.study_acronym or 'Study'} - {data.study_identification.title[:60]}...")
        
        # Create tabs for detailed information using card-based displays
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìÑ Study Design", "üìä Results & Efficacy", "üë• Patient Population", "üíä Treatment Regimens", "‚ö†Ô∏è Safety Profile"])
        
        with tab1:
            self._display_study_design_tab(data)
        
        with tab2:
            self._display_results_efficacy_tab(data)
        
        with tab3:
            self._display_patient_population_tab(data)
        
        with tab4:
            self._display_treatment_regimens_tab(data)
        
        with tab5:
            self._display_safety_profile_tab(data)

    def _generate_treatment_distribution_table(self) -> Dict[str, Any]:
        """Generate treatment distribution table by therapy category and patient population"""
        
        # Define therapy categories and their examples
        therapy_categories = {
            'BCMA-CAR-T Therapies': ['cilta-cel', 'ciltacabtagene', 'ide-cel', 'idecabtagene', 'car-t', 'cart', 'ARI0002h'],
            'BCMA-Bispecific Ab Therapies': ['teclistamab', 'talquetamab', 'elranatamab', 'linvoseltamab', 'ABBV-383', 'bispecific'],
            'ADC': ['belantamab', 'belantamab mafodotin', 'elotuzumab', 'adc', 'antibody-drug conjugate'],
            'Cereblon E3 Ligase Modulator': ['mezigdomide', 'iberdomide', 'cereblon', 'e3 ligase'],
            'Triplet/Quadruplet SOC': ['vrd', 'isa-vrd', 'isatuximab', 'lenalidomide', 'bortezomib', 'dexamethasone', 'daratumumab'],
            'Transplantation': ['asct', 'transplant', 'stem cell', 'autologous'],
            'Others': []  # Will be populated with unmatched treatments
        }
        
        # Population mapping
        population_mapping = {
            'RRMM': ['relapsed', 'refractory', 'rrmm', 'r/r'],
            'NDMM': ['newly diagnosed', 'ndmm', 'first-line', 'frontline']
        }
        
        treatment_distribution = {}
        
        for data in st.session_state.extracted_data:
            # Determine patient population - Use extracted mm_subtype data first
            population = 'Unknown'
            
            # Define title_lower at the beginning so it's always available
            title_lower = data.study_identification.title.lower() if data.study_identification.title else ''
            
            # First, check the extracted disease characteristics data
            if data.disease_characteristics and data.disease_characteristics.mm_subtype:
                # Get the first mm_subtype (most relevant one)
                mm_subtype = data.disease_characteristics.mm_subtype[0].value
                if 'Relapsed' in mm_subtype or 'Refractory' in mm_subtype:
                    population = 'RRMM'
                elif 'Newly Diagnosed' in mm_subtype:
                    population = 'NDMM'
            
            # Fallback to title-based detection if no extracted data
            if population == 'Unknown':
                # Check for RRMM
                if any(keyword in title_lower for keyword in population_mapping['RRMM']):
                    population = 'RRMM'
                # Check for NDMM
                elif any(keyword in title_lower for keyword in population_mapping['NDMM']):
                    population = 'NDMM'
                # Also check treatment regimens for population indicators
                else:
                    regimens_text = ''
                    if data.treatment_regimens:
                        for regimen in data.treatment_regimens:
                            if regimen.regimen_name:
                                regimens_text += regimen.regimen_name.lower() + ' '
                    
                    if any(keyword in regimens_text for keyword in population_mapping['RRMM']):
                        population = 'RRMM'
                    elif any(keyword in regimens_text for keyword in population_mapping['NDMM']):
                        population = 'NDMM'
            
            # Extract treatment information
            treatments_found = []
            if data.treatment_regimens:
                for regimen in data.treatment_regimens:
                    if regimen.regimen_name:
                        treatments_found.append(regimen.regimen_name.lower())
                    if regimen.drugs:
                        # Handle both string and dictionary drug formats
                        for drug in regimen.drugs:
                            if isinstance(drug, dict):
                                # Extract drug name from dictionary
                                drug_name = drug.get('name', '')
                                if drug_name:
                                    treatments_found.append(drug_name.lower())
                            elif isinstance(drug, str):
                                treatments_found.append(drug.lower())
            
            # Also check title for treatment mentions
            treatments_found.append(title_lower)
            treatments_text = ' '.join(treatments_found)
            
            # Categorize treatment
            therapy_category = 'Others'
            for category, keywords in therapy_categories.items():
                if any(keyword in treatments_text for keyword in keywords):
                    therapy_category = category
                    break
            
            # Initialize nested structure if needed
            if population not in treatment_distribution:
                treatment_distribution[population] = {}
            
            if therapy_category not in treatment_distribution[population]:
                treatment_distribution[population][therapy_category] = {
                    'studies': [],
                    'examples': set()
                }
            
            # Add study and examples
            study_info = {
                'title': data.study_identification.title,
                'acronym': data.study_identification.study_acronym
            }
            treatment_distribution[population][therapy_category]['studies'].append(study_info)
            
            # Extract specific drug examples
            if data.treatment_regimens:
                for regimen in data.treatment_regimens:
                    if regimen.regimen_name:
                        treatment_distribution[population][therapy_category]['examples'].add(regimen.regimen_name)
                    if regimen.drugs:
                        for drug in regimen.drugs:
                            if isinstance(drug, dict):
                                # Extract drug name from dictionary
                                drug_name = drug.get('name', '')
                                if drug_name:
                                    treatment_distribution[population][therapy_category]['examples'].add(drug_name)
                            elif isinstance(drug, str):
                                treatment_distribution[population][therapy_category]['examples'].add(drug)
        
        # Format for display
        formatted_distribution = {}
        total_studies = len(st.session_state.extracted_data)
        
        for population, categories in treatment_distribution.items():
            formatted_distribution[population] = []
            population_total = sum(len(cat_data['studies']) for cat_data in categories.values())
            
            for category, cat_data in categories.items():
                study_count = len(cat_data['studies'])
                if study_count > 0:  # Only include categories with studies
                    percentage = (study_count / population_total * 100) if population_total > 0 else 0
                    examples = list(cat_data['examples'])[:3]  # Limit to 3 examples
                    
                    formatted_distribution[population].append({
                        'category': category,
                        'examples': ', '.join(examples) if examples else 'N/A',
                        'count': study_count,
                        'percentage': percentage,
                        'studies': cat_data['studies']
                    })
            
            # Sort by count descending
            formatted_distribution[population].sort(key=lambda x: x['count'], reverse=True)
        
        return {
            'distribution': formatted_distribution,
            'total_studies': total_studies,
            'populations': list(formatted_distribution.keys())
        }

    def _display_treatment_distribution_table(self, distribution_data: Dict[str, Any]):
        """Display the treatment distribution table"""
        
        st.markdown("""
        <div class="section-header">
            <h3>üíä Treatment Distribution Analysis</h3>
        </div>
        """, unsafe_allow_html=True)
        
        if not distribution_data['distribution']:
            st.info("üìä Upload multiple abstracts to see treatment distribution analysis")
            return
        
        total_studies = distribution_data['total_studies']
        st.markdown(f"**Treatment distribution across your {total_studies} studies**")
        
        # Create comprehensive table
        table_data = []
        
        for population in ['RRMM', 'NDMM', 'Unknown']:
            if population in distribution_data['distribution']:
                categories = distribution_data['distribution'][population]
                population_total = sum(cat['count'] for cat in categories)
                
                # Add population header
                if categories:
                    table_data.append({
                        'Population': f"**{population}** (N={population_total})",
                        'Therapy Category': '',
                        'Examples': '',
                        'No. of Studies': '',
                        '%': ''
                    })
                
                for category in categories:
                    table_data.append({
                        'Population': '',
                        'Therapy Category': category['category'],
                        'Examples': category['examples'],
                        'No. of Studies': str(category['count']),
                        '%': f"{category['percentage']:.1f}%"
                    })
        
        if table_data:
            # Convert to DataFrame for better display
            import pandas as pd
            df = pd.DataFrame(table_data)
            
            # Style the table
            st.markdown("""
            <style>
            .treatment-table {
                font-size: 0.9rem;
                width: 100%;
            }
            .treatment-table th {
                background-color: #f8fafc;
                font-weight: 600;
                padding: 0.75rem;
                border-bottom: 2px solid #e2e8f0;
            }
            .treatment-table td {
                padding: 0.5rem 0.75rem;
                border-bottom: 1px solid #e2e8f0;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # Display as HTML table for better formatting
            html_table = df.to_html(classes='treatment-table', escape=False, index=False)
            st.markdown(html_table, unsafe_allow_html=True)
            
            # Add download option
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="üì• Download Treatment Distribution Table",
                data=csv_data,
                file_name="treatment_distribution.csv",
                mime="text/csv",
                help="Download the treatment distribution table as CSV"
            )
        else:
            st.info("üìä No treatment categories detected in your studies")

    def _safe_get(self, obj, path: str, default=None):
        """Safely get nested attributes from object or dictionary"""
        try:
            keys = path.split('.')
            current = obj
            for key in keys:
                if isinstance(current, dict):
                    current = current.get(key, default)
                else:
                    current = getattr(current, key, default)
                if current is None:
                    return default
            return current
        except:
            return default

    def _generate_high_risk_population_analysis(self) -> Dict[str, Any]:
        """Generate high-risk population analysis across all studies"""
        
        high_risk_data = {
            'cytogenetic_abnormalities': {'studies': [], 'total_count': 0},
            'extramedullary_disease': {'studies': [], 'total_count': 0}, 
            'elderly_patients': {'studies': [], 'total_count': 0},
            'high_risk_general': {'studies': [], 'total_count': 0},
            'total_studies': len(st.session_state.extracted_data),
            'studies_with_high_risk_data': 0
        }
        
        for i, data in enumerate(st.session_state.extracted_data):
            has_high_risk_data = False
            
            # Check for cytogenetic abnormalities
            cytogenetic_abnormalities = self._safe_get(data, 'disease_characteristics.cytogenetic_abnormalities')
            if cytogenetic_abnormalities and isinstance(cytogenetic_abnormalities, list):
                for abnormality in cytogenetic_abnormalities:
                    if isinstance(abnormality, dict):
                        count = abnormality.get('count', 0) or abnormality.get('percentage', 0)
                        if count:
                            high_risk_data['cytogenetic_abnormalities']['studies'].append({
                                'study': data.study_identification.study_acronym or f"Study {i+1}",
                                'title': data.study_identification.title,
                                'details': abnormality,
                                'count': count
                            })
                            high_risk_data['cytogenetic_abnormalities']['total_count'] += int(count) if isinstance(count, (int, float)) else 1
                            has_high_risk_data = True
            
            # Check for high-risk percentage (general)
            high_risk_pct = self._safe_get(data, 'disease_characteristics.high_risk_percentage')
            if high_risk_pct:
                total_enrolled = data.patient_demographics.total_enrolled or 100  # Default denominator
                estimated_count = int((high_risk_pct / 100) * total_enrolled)
                high_risk_data['high_risk_general']['studies'].append({
                    'study': data.study_identification.study_acronym or f"Study {i+1}",
                    'title': data.study_identification.title,
                    'percentage': high_risk_pct,
                    'estimated_count': estimated_count,
                    'total_enrolled': total_enrolled
                })
                high_risk_data['high_risk_general']['total_count'] += estimated_count
                has_high_risk_data = True
            
            # Check for extramedullary disease
            emd_pct = self._safe_get(data, 'disease_characteristics.extramedullary_disease_percentage')
            if emd_pct:
                total_enrolled = data.patient_demographics.total_enrolled or 100
                estimated_count = int((emd_pct / 100) * total_enrolled)
                high_risk_data['extramedullary_disease']['studies'].append({
                    'study': data.study_identification.study_acronym or f"Study {i+1}",
                    'title': data.study_identification.title,
                    'percentage': emd_pct,
                    'estimated_count': estimated_count,
                    'total_enrolled': total_enrolled
                })
                high_risk_data['extramedullary_disease']['total_count'] += estimated_count
                has_high_risk_data = True
            
            # Check for elderly patients
            elderly_pct = self._safe_get(data, 'patient_demographics.elderly_percentage')
            very_elderly_pct = self._safe_get(data, 'patient_demographics.very_elderly_percentage')
            
            if elderly_pct or very_elderly_pct:
                total_enrolled = data.patient_demographics.total_enrolled or 100
                # Use the higher percentage if both are available
                elderly_percentage = max(elderly_pct or 0, very_elderly_pct or 0)
                estimated_count = int((elderly_percentage / 100) * total_enrolled)
                
                high_risk_data['elderly_patients']['studies'].append({
                    'study': data.study_identification.study_acronym or f"Study {i+1}",
                    'title': data.study_identification.title,
                    'elderly_pct': elderly_pct,
                    'very_elderly_pct': very_elderly_pct,
                    'estimated_count': estimated_count,
                    'total_enrolled': total_enrolled
                })
                high_risk_data['elderly_patients']['total_count'] += estimated_count
                has_high_risk_data = True
            
            if has_high_risk_data:
                high_risk_data['studies_with_high_risk_data'] += 1
        
        return high_risk_data

    def _display_high_risk_population_analysis(self, high_risk_data: Dict[str, Any]):
        """Display high-risk population analysis"""
        
        if high_risk_data['studies_with_high_risk_data'] == 0:
            st.info("üìä No high-risk population data found in current studies")
            return
        
        st.markdown("""
        <div class="section-header">
            <h3>‚ö†Ô∏è High-Risk Population Analysis</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Summary statistics
        total_studies = high_risk_data['total_studies']
        studies_with_data = high_risk_data['studies_with_high_risk_data']
        
        st.markdown(f"""
        **{studies_with_data} of {total_studies} studies included high-risk populations with the following characteristics:**
        """)
        
        # Create summary table
        summary_data = []
        
        # Cytogenetic abnormalities
        cyto_studies = len(high_risk_data['cytogenetic_abnormalities']['studies'])
        cyto_total = high_risk_data['cytogenetic_abnormalities']['total_count']
        if cyto_studies > 0:
            summary_data.append({
                'High-Risk Category': 'Cytogenetic Abnormalities',
                'No. of Studies': cyto_studies,
                'Estimated Patients (n)': cyto_total,
                'Details': f"Studies with high-risk cytogenetics data"
            })
        
        # Extramedullary disease
        emd_studies = len(high_risk_data['extramedullary_disease']['studies'])
        emd_total = high_risk_data['extramedullary_disease']['total_count']
        if emd_studies > 0:
            summary_data.append({
                'High-Risk Category': 'Extramedullary Disease',
                'No. of Studies': emd_studies,
                'Estimated Patients (n)': emd_total,
                'Details': f"Studies reporting EMD presence"
            })
        
        # Elderly patients
        elderly_studies = len(high_risk_data['elderly_patients']['studies'])
        elderly_total = high_risk_data['elderly_patients']['total_count']
        if elderly_studies > 0:
            summary_data.append({
                'High-Risk Category': 'Elderly Patients (‚â•65 years)',
                'No. of Studies': elderly_studies,
                'Estimated Patients (n)': elderly_total,
                'Details': f"Studies with elderly population data"
            })
        
        # General high-risk
        hr_studies = len(high_risk_data['high_risk_general']['studies'])
        hr_total = high_risk_data['high_risk_general']['total_count']
        if hr_studies > 0:
            summary_data.append({
                'High-Risk Category': 'General High-Risk',
                'No. of Studies': hr_studies,
                'Estimated Patients (n)': hr_total,
                'Details': f"Studies with general high-risk designation"
            })
        
        if summary_data:
            import pandas as pd
            df = pd.DataFrame(summary_data)
            
            # Style the table
            st.markdown("""
            <style>
            .high-risk-table {
                font-size: 0.9rem;
                width: 100%;
            }
            .high-risk-table th {
                background-color: #fef3c7;
                font-weight: 600;
                padding: 0.75rem;
                border-bottom: 2px solid #f59e0b;
            }
            .high-risk-table td {
                padding: 0.5rem 0.75rem;
                border-bottom: 1px solid #e2e8f0;
            }
            </style>
            """, unsafe_allow_html=True)
            
            html_table = df.to_html(classes='high-risk-table', escape=False, index=False)
            st.markdown(html_table, unsafe_allow_html=True)
            
            # Detailed breakdown in expandable sections
            with st.expander("üîç View Detailed Breakdown", expanded=False):
                
                # Cytogenetic abnormalities details
                if high_risk_data['cytogenetic_abnormalities']['studies']:
                    st.markdown("#### üß¨ Cytogenetic Abnormalities")
                    for study_data in high_risk_data['cytogenetic_abnormalities']['studies']:
                        st.markdown(f"**{study_data['study']}:** {study_data['details']}")
                
                # Extramedullary disease details
                if high_risk_data['extramedullary_disease']['studies']:
                    st.markdown("#### üîÑ Extramedullary Disease")
                    for study_data in high_risk_data['extramedullary_disease']['studies']:
                        st.markdown(f"**{study_data['study']}:** {study_data['percentage']}% ({study_data['estimated_count']} patients)")
                
                # Elderly patients details
                if high_risk_data['elderly_patients']['studies']:
                    st.markdown("#### üë¥ Elderly Patients")
                    for study_data in high_risk_data['elderly_patients']['studies']:
                        elderly_info = f"{study_data['elderly_pct']}%" if study_data['elderly_pct'] else ""
                        very_elderly_info = f"(‚â•75: {study_data['very_elderly_pct']}%)" if study_data['very_elderly_pct'] else ""
                        st.markdown(f"**{study_data['study']}:** {elderly_info} {very_elderly_info} (~{study_data['estimated_count']} patients)")
                
                # General high-risk details
                if high_risk_data['high_risk_general']['studies']:
                    st.markdown("#### ‚ö†Ô∏è General High-Risk Populations")
                    for study_data in high_risk_data['high_risk_general']['studies']:
                        st.markdown(f"**{study_data['study']}:** {study_data['percentage']}% ({study_data['estimated_count']} patients)")
        
        # Download option
        if summary_data:
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="üì• Download High-Risk Population Analysis",
                data=csv_data,
                file_name="high_risk_population_analysis.csv",
                mime="text/csv",
                help="Download the high-risk population analysis as CSV"
            )

def main():
    """Main application entry point"""
    app = ASCOmindApp()
    app.run()


if __name__ == "__main__":
    main() 